<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    
    <title>第7章  Spark Streaming | 锦鲤未离</title>

    <meta name="description" content="锦鲤未离">
    <meta name="keywords" content="">

    

    <meta property="og:locale" content="zh-CN" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content= "第7章  Spark Streaming | 锦鲤未离"  />
    <meta property="og:description" content= "锦鲤未离" />
    <meta property="og:url" content="http://example.com/posts/spark_07/index.html" />
    <meta property="og:site_name" content="" />
    <meta property="article:author" content="Koi_NL" />
    <meta property="article:publisher" content="" />
    <meta property="og:description" content="锦鲤未离" />
    <meta name="twitter:title" content="第7章  Spark Streaming | 锦鲤未离"/>
    <meta name="twitter:description" content="锦鲤未离"/>
    <script type="application/ld+json">
        {
            "description": "锦鲤未离",
            "author": { "@type": "Person", "name": "Koi_NL" },
            "@type": "BlogPosting",
            "url": "http://example.com/posts/spark_07/index.html",
            "publisher": {
            "@type": "Organization",
            "logo": {
                "@type": "ImageObject",
                "url": "http://example.comundefined"
            },
            "name": "Koi_NL"
            },
            "headline": "第7章  Spark Streaming | 锦鲤未离",
            "datePublished": "2023-03-19T00:56:01.672Z",
            "mainEntityOfPage": {
                "@type": "WebPage",
                "@id": "http://example.com/posts/spark_07/index.html"
            },
            "@context": "http://schema.org"
        }
    </script>




    

    

    

    

    

    

    

    
<link rel="stylesheet" href="/dist/build.css?v=1654266144177.css">


    
<link rel="stylesheet" href="/dist/custom.css?v=1654266144177.css">


    <script>
        window.isPost = true
        window.aomori = {
            
            
            
        }
        window.aomori_logo_typed_animated = false
        window.aomori_search_algolia = false

    </script>

<meta name="generator" content="Hexo 6.1.0"></head>

<body>

    <div class="container">
    <header class="header">
        <div class="header-type">
            
            <div class="header-type-inner">
                
                    <a class="header-type-title" href="/">锦鲤未离</a>
                
    
                
            </div>
        </div>
        <div class="header-menu">
            <div class="header-menu-inner">
                
            </div>
            <div class="header-menu-social">
                
            </div>
        </div>

        <div class="header-menu-mobile">
            <div class="header-menu-mobile-inner" id="mobile-menu-open">
                <i class="icon icon-menu"></i>
            </div>
        </div>
    </header>

    <div class="header-menu-mobile-menu">
        <div class="header-menu-mobile-menu-bg"></div>
        <div class="header-menu-mobile-menu-wrap">
            <div class="header-menu-mobile-menu-inner">
                <div class="header-menu-mobile-menu-close" id="mobile-menu-close">
                    <i class="icon icon-cross"></i>
                </div>
                <div class="header-menu-mobile-menu-list">
                    
                </div>
            </div>
        </div>
    </div>

</div>

    <div class="container">
        <div class="main">
            <section class="inner">
                <section class="inner-main">
                    <div class="post">
    <article id="post-clferl2ka0000eg104b07bi9s" class="article article-type-post" itemscope
    itemprop="blogPost">

    <div class="article-inner">

        
          
        
        
        

        
        <header class="article-header">
            
  
    <h1 class="article-title" itemprop="name">
      第7章  Spark Streaming
    </h1>
  

        </header>
        

        <div class="article-more-info article-more-info-post hairline">

            <div class="article-date">
  <time datetime="2023-03-19T00:56:01.672Z" itemprop="datePublished">2023-03-19</time>
</div>

            
            <div class="article-category">
                <a class="article-category-link" href="/categories/spark/">spark</a>
            </div>
            

            

            

        </div>

        <div class="article-entry post-inner-html hairline" itemprop="articleBody">
            <p>Spark Streaming是实时计算框架，主要为了对数据进行实时处理。<br>首先，简单了解了Spark Streaming的基础知识。<br>其次，Spark Streaming的核心是DStream，因此该小节最终以实例——实现网站热词排序来体现。<br>最后，将Spark Streaming整合Kafka，来实现词频统计。</p>
<h2 id="Kafka-Streaming开发单词计数应用"><a href="#Kafka-Streaming开发单词计数应用" class="headerlink" title="Kafka Streaming开发单词计数应用"></a>Kafka Streaming开发单词计数应用</h2><h3 id="1-添加依赖"><a href="#1-添加依赖" class="headerlink" title="1. 添加依赖"></a>1. 添加依赖</h3><p>打开 pom.xml 文件，添加 Kafka Streamimh 整合 Kafka的 依赖，注意匹配版本号。</p>
<details ><summary>添加依赖代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--引入sparkstreaming整合kafka的依赖--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-streaming-kafka_0-<span class="number">8_2.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">2.3</span><span class="number">.2</span>&lt;/version&gt;</span><br><span class="line">  &lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></details>

<h3 id="2-编写代码"><a href="#2-编写代码" class="headerlink" title="2. 编写代码"></a>2. 编写代码</h3><ul>
<li>文件 LogProcessor.java，单词计数的业务功能开发<br>在spark_ chapter07项目的&#x2F;src&#x2F;main&#x2F;scala&#x2F;cn.itcast.dstream目录下， 创建一个名为”SparkStreaming Kafka_createDstream”的Scala类，用来编写Spark Streaming应用程序实现词频统计。<details ><summary>Spark Streaming应用程序实现词频统计的Java代码</summary><div class="fold-content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.serializer.StringDecoder</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;DStream, InputDStream&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.KafkaUtils</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;Seconds, StreamingContext&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">object SparkStreaming_Kafka_createDirectStream &#123;</span><br><span class="line">    def <span class="title function_">main</span><span class="params">(args: Array[String])</span>: Unit = &#123;</span><br><span class="line">        <span class="comment">//1.创建sparkConf对象，用于配置Spark环境</span></span><br><span class="line">        val sparkConf: SparkConf = <span class="keyword">new</span> <span class="title class_">SparkConf</span>()</span><br><span class="line">                .setAppName(<span class="string">&quot;SparkStreaming_Kafka_createDirectStream&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="comment">//2.创建sparkContext对象，用于操作Spark集群</span></span><br><span class="line">        <span class="type">val</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkContext</span>(sparkConf)</span><br><span class="line">        <span class="comment">//3.设置日志输出级别</span></span><br><span class="line">        sc.setLogLevel(<span class="string">&quot;WARN&quot;</span>)</span><br><span class="line">        <span class="comment">//4.创建StreamingContext对象，用于创建DStream对象</span></span><br><span class="line">        <span class="type">val</span> <span class="variable">ssc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StreamingContext</span>(sc,Seconds(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">//5.通过ssc对象设置chectPoint（检查点）</span></span><br><span class="line">        ssc.checkpoint(<span class="string">&quot;./Kafka_Direct&quot;</span>)</span><br><span class="line">        <span class="comment">//6.配置kafka相关参数 （metadata.broker.list为老版本的集群地址）</span></span><br><span class="line">        val kafkaParams=Map(<span class="string">&quot;metadata.broker.list&quot;</span>-&gt;<span class="string">&quot;hadoop01:9092,hadoop02:9092,hadoop03:9092&quot;</span>,<span class="string">&quot;group.id&quot;</span>-&gt;<span class="string">&quot;spark_direct&quot;</span>)</span><br><span class="line">        <span class="comment">//7.定义topic</span></span><br><span class="line">        val topics=Set(<span class="string">&quot;kafka_direct0&quot;</span>)</span><br><span class="line">        <span class="comment">//8.通过低级api方式将kafka与sparkStreaming进行整合</span></span><br><span class="line">        val dstream: InputDStream[(String, String)] =</span><br><span class="line">KafkaUtils.createDirectStream[String,String,StringDecoder,StringDecoder](ssc,kafkaParams,topics)</span><br><span class="line">        <span class="comment">//9.获取kafka中topic中的数据</span></span><br><span class="line">        val topicData: DStream[String] = dstream.map(_._2)</span><br><span class="line">        <span class="comment">//10.通过flatMap()和map()方法转换操作按空格进行切分每一行,并将切分的单词出现次数记录为1</span></span><br><span class="line">        val wordAndOne: DStream[(String, Int)] = topicData.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,<span class="number">1</span>))</span><br><span class="line">        <span class="comment">//11.通过reduceByKey（）方法转换操作统计单词在全局中出现的次数</span></span><br><span class="line">        val result: DStream[(String, Int)] = wordAndOne.reduceByKey(_+_)</span><br><span class="line">        <span class="comment">//12.打印输出结果</span></span><br><span class="line">        result.print()</span><br><span class="line">        <span class="comment">//13.开启流式计算</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></details>
运行上述代码后，依次在hadoop01、hadoop02、hadoop03服务器执行命令<code>zkServer.sh start</code>启动ZooKeeper集群；然后再依次在Kafka的根目录下执行命令<code>bin/kafka-server-start.sh config/server.properties</code>启动Kafka集群。</li>
</ul>
<ol>
<li>创建Topic, 指定消息的类别<details ><summary>创建来源主题和目标主题代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create \</span><br><span class="line">--topic kafka_direct0 \</span><br><span class="line">--partitions <span class="number">3</span> \</span><br><span class="line">--replication-factor <span class="number">1</span> \</span><br><span class="line">--zookeeper hadoop01:<span class="number">2181</span>,hadoop02:<span class="number">2181</span>,hadoop03:<span class="number">2181</span></span><br></pre></td></tr></table></figure></div></details></li>
<li>在hadoop01启动生产者服务，生产数据<details ><summary>启动生产者服务和消费者服务代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-<span class="built_in">list</span> hadoop01:<span class="number">9092</span> --topic kafka_direct0</span><br></pre></td></tr></table></figure></div></details></li>
<li>在生产者服务节点（hadoop01）输入hello kafka kafka语句，可在IDEA工具中查看控制台，可以看到控制台输出了{hello&#x3D;1, kafka&#x3D;2}信息</li>
</ol>

        </div>

    </div>

    

    

    

    

    

    
<nav class="article-nav">
  
    <a href="/posts/spark_08/" id="article-nav-newer" class="article-nav-link-wrap">
      <div class="article-nav-caption">下一篇</div>
      <div class="article-nav-title">
        
          第8章  Spark MLlib机器学习算法库
        
      </div>
    </a>
  
  
    <a href="/posts/spark_06/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-caption">上一篇</div>
      <div class="article-nav-title">第6章  Kafka分布式发布订阅消息系统</div>
    </a>
  
</nav>


    <section class="share">
        <div class="share-title">分享</div>
        <a class="share-item" target="_blank"
            href="https://twitter.com/share?text=第7章  Spark Streaming - 锦鲤未离&url=http%3A%2F%2Fexample.com%2Fposts%2Fspark_07%2F">
            <ion-icon name="logo-twitter"></ion-icon>
        </a>
        <a class="share-item" target="_blank"
            href="https://www.facebook.com/sharer.php?title=第7章  Spark Streaming - 锦鲤未离&u=http%3A%2F%2Fexample.com%2Fposts%2Fspark_07%2F">
            <ion-icon name="logo-facebook"></ion-icon>
        </a>
        <!-- <a class="share-item" target="_blank"
            href="https://service.weibo.com/share/share.php?title=第7章  Spark Streaming - 锦鲤未离&url=http://example.com/posts/spark_07/&pic=">
            <div class="n-icon n-icon-weibo"></div>
        </a> -->
    </section>

</article>
















</div>
                </section>
            </section>

            
            <aside class="sidebar ">
                


<div class="widget" id="widget">
    
      
  <div class="widget-wrap">
    <div class="widget-inner">
      <div class="toc post-toc-html"></div>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-cate">
    <div class="widget-title"><span>Categories</span></div>
    <div class="widget-inner">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Applied-Statistics/">Applied Statistics</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure-and-Algorithm/">Data Structure and Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Mining/">Data-Mining</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Processing-and-Analysing/">Data-Processing-and-Analysing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATLAB/">MATLAB</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/SqlServer/">SqlServer</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/">时间序列分析</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B5%8B%E8%AF%95%E5%8C%BA/">测试区</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">深度卷积神经网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87/">电子设备</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%80%83%E8%AF%95/">考试</a></li></ul>
    </div>
  </div>


    
      

    
      
  <div class="widget-wrap widget-recent-posts">
    <div class="widget-title"><span>Recent Posts</span></div>
    <div class="widget-inner">
      <ul>
        
          <li>
            <a href="/posts/spark_05/">第5章  HBase 分布式数据库</a>
          </li>
        
          <li>
            <a href="/posts/spark_04/">第4章  Spark SQL结构化数据文件处理</a>
          </li>
        
          <li>
            <a href="/posts/spark_01/">第1章  Scala语言基础.</a>
          </li>
        
          <li>
            <a href="/posts/spark_03/">第3章  Spark RDD弹性分布式数据集</a>
          </li>
        
          <li>
            <a href="/posts/spark_08/">第8章  Spark MLlib机器学习算法库</a>
          </li>
        
      </ul>
    </div>
  </div>

    
      
  <div class="widget-wrap widget-archive">
    <div class="widget-title"><span>Archive</span></div>
    <div class="widget-inner">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/">2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1999/">1999</a></li></ul>
    </div>
  </div>


    
</div>

<div id="backtop"><i class="icon icon-arrow-up"></i></div>
            </aside>
            
        </div>
    </div>

    <footer class="footer">
    <div class="footer-wave">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1440 320"><path fill="#3c4859" fill-opacity="1" d="M0,160L60,181.3C120,203,240,245,360,240C480,235,600,181,720,186.7C840,192,960,256,1080,261.3C1200,267,1320,213,1380,186.7L1440,160L1440,320L1380,320C1320,320,1200,320,1080,320C960,320,840,320,720,320C600,320,480,320,360,320C240,320,120,320,60,320L0,320Z"></path></svg>
    </div>

    <!-- Please do not remove this -->
    <!-- 开源不易，请勿删除 -->
    <div class="footer-wrap">
        <div class="footer-inner"> 
            锦鲤未离 &copy; 2023<br>
            Powered By Hexo · Theme By <a href="https://linhong.me/" target="_blank">Aomori</a> · <a href="https://github.com/lh1me/hexo-theme-aomori" target="_blank">Github</a>
        </div>
    </div>

</footer>

<script type="module" src="https://unpkg.com/ionicons@6.0.2/dist/ionicons/ionicons.esm.js"></script>






<script src="/dist/build.js?1654266144177.js"></script>


<script src="/dist/custom.js?1654266144177.js"></script>













</body>

</html>