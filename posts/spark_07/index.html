<!DOCTYPE html>
<html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init">
<head>
  <meta charset="utf-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

  <link rel="icon" href="/favicon.ico">
  
  <title>锦鲤未离 | 第7章  Spark Streaming</title>
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/lib/fancybox/jquery.fancybox-1.3.4.css">

  <!--在这里倒入jquery 方便处理部分页面的jquery-->
  <script src="https://cdn.staticfile.org/jquery/1.7/jquery.min.js" type="text/javascript" ></script>
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
	<header class="site-header navfixed-false">
  <div class="container">
      <h1><a href="/" title="锦鲤未离"><span class="octicon octicon-mark-github"></span> 锦鲤未离</a></h1>
      <nav class="site-header-nav" role="navigation">
        
              
              <a href="/"  class=" site-header-nav-item hvr-underline-from-center" title="Home">Home</a>
        
              
              <a href="/categories/"  class=" site-header-nav-item hvr-underline-from-center" title="Category">Category</a>
        
              
              <a href="/open-source/"  class=" site-header-nav-item hvr-underline-from-center" title="Open-Source">Open-Source</a>
        
              
              <a href="/message/"  class=" site-header-nav-item hvr-underline-from-center" title="Message">Message</a>
        
      </nav>
  </div>
</header>

	
<section class="collection-head geopattern" data-pattern-id="第7章  Spark Streaming" >
    <div class="container">
        <div class="collection-title">
            <h1 class="collection-header">
                第7章  Spark Streaming
            </h1>
            
                <div class="collection-info">
                    <span class="meta-info">
                        <span class="octicon octicon-calendar"></span>
                        <time datetime="2023-03-19T00:56:01.672Z" itemprop="datePublished">2023-03-19</time>
                    </span>
                    
                        <span class="meta-info">
                            <span class="octicon octicon-file-directory"></span>
                            <a href='/categories/spark/' title=''>spark</a>
                        </span>
                    
                </div>
            
        </div>
    </div>
</section>
	<section class="container">
    <div class="columns">
        <div class="column  three-fourths " >
            <article class="article-content markdown-body">
                <p>Spark Streaming是实时计算框架，主要为了对数据进行实时处理。<br>首先，简单了解了Spark Streaming的基础知识。<br>其次，Spark Streaming的核心是DStream，因此该小节最终以实例——实现网站热词排序来体现。<br>最后，将Spark Streaming整合Kafka，来实现词频统计。</p>
<h2 id="Kafka-Streaming开发单词计数应用"><a href="#Kafka-Streaming开发单词计数应用" class="headerlink" title="Kafka Streaming开发单词计数应用"></a>Kafka Streaming开发单词计数应用</h2><h3 id="1-添加依赖"><a href="#1-添加依赖" class="headerlink" title="1. 添加依赖"></a>1. 添加依赖</h3><p>打开 pom.xml 文件，添加 Kafka Streamimh 整合 Kafka的 依赖，注意匹配版本号。</p>
<details ><summary>添加依赖代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--引入sparkstreaming整合kafka的依赖--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-streaming-kafka_0-<span class="number">8_2.11</span>&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;<span class="number">2.3</span><span class="number">.2</span>&lt;/version&gt;</span><br><span class="line">  &lt;/dependency&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div></details>

<h3 id="2-编写代码"><a href="#2-编写代码" class="headerlink" title="2. 编写代码"></a>2. 编写代码</h3><ul>
<li>文件 LogProcessor.java，单词计数的业务功能开发<br>在spark_ chapter07项目的&#x2F;src&#x2F;main&#x2F;scala&#x2F;cn.itcast.dstream目录下， 创建一个名为”SparkStreaming Kafka_createDstream”的Scala类，用来编写Spark Streaming应用程序实现词频统计。<details ><summary>Spark Streaming应用程序实现词频统计的Java代码</summary><div class="fold-content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.serializer.StringDecoder</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.&#123;DStream, InputDStream&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.KafkaUtils</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;Seconds, StreamingContext&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">object SparkStreaming_Kafka_createDirectStream &#123;</span><br><span class="line">    def <span class="title function_">main</span><span class="params">(args: Array[String])</span>: Unit = &#123;</span><br><span class="line">        <span class="comment">//1.创建sparkConf对象，用于配置Spark环境</span></span><br><span class="line">        val sparkConf: SparkConf = <span class="keyword">new</span> <span class="title class_">SparkConf</span>()</span><br><span class="line">                .setAppName(<span class="string">&quot;SparkStreaming_Kafka_createDirectStream&quot;</span>).setMaster(<span class="string">&quot;local[2]&quot;</span>)</span><br><span class="line">        <span class="comment">//2.创建sparkContext对象，用于操作Spark集群</span></span><br><span class="line">        <span class="type">val</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkContext</span>(sparkConf)</span><br><span class="line">        <span class="comment">//3.设置日志输出级别</span></span><br><span class="line">        sc.setLogLevel(<span class="string">&quot;WARN&quot;</span>)</span><br><span class="line">        <span class="comment">//4.创建StreamingContext对象，用于创建DStream对象</span></span><br><span class="line">        <span class="type">val</span> <span class="variable">ssc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StreamingContext</span>(sc,Seconds(<span class="number">5</span>))</span><br><span class="line">        <span class="comment">//5.通过ssc对象设置chectPoint（检查点）</span></span><br><span class="line">        ssc.checkpoint(<span class="string">&quot;./Kafka_Direct&quot;</span>)</span><br><span class="line">        <span class="comment">//6.配置kafka相关参数 （metadata.broker.list为老版本的集群地址）</span></span><br><span class="line">        val kafkaParams=Map(<span class="string">&quot;metadata.broker.list&quot;</span>-&gt;<span class="string">&quot;hadoop01:9092,hadoop02:9092,hadoop03:9092&quot;</span>,<span class="string">&quot;group.id&quot;</span>-&gt;<span class="string">&quot;spark_direct&quot;</span>)</span><br><span class="line">        <span class="comment">//7.定义topic</span></span><br><span class="line">        val topics=Set(<span class="string">&quot;kafka_direct0&quot;</span>)</span><br><span class="line">        <span class="comment">//8.通过低级api方式将kafka与sparkStreaming进行整合</span></span><br><span class="line">        val dstream: InputDStream[(String, String)] =</span><br><span class="line">KafkaUtils.createDirectStream[String,String,StringDecoder,StringDecoder](ssc,kafkaParams,topics)</span><br><span class="line">        <span class="comment">//9.获取kafka中topic中的数据</span></span><br><span class="line">        val topicData: DStream[String] = dstream.map(_._2)</span><br><span class="line">        <span class="comment">//10.通过flatMap()和map()方法转换操作按空格进行切分每一行,并将切分的单词出现次数记录为1</span></span><br><span class="line">        val wordAndOne: DStream[(String, Int)] = topicData.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,<span class="number">1</span>))</span><br><span class="line">        <span class="comment">//11.通过reduceByKey（）方法转换操作统计单词在全局中出现的次数</span></span><br><span class="line">        val result: DStream[(String, Int)] = wordAndOne.reduceByKey(_+_)</span><br><span class="line">        <span class="comment">//12.打印输出结果</span></span><br><span class="line">        result.print()</span><br><span class="line">        <span class="comment">//13.开启流式计算</span></span><br><span class="line">        ssc.start()</span><br><span class="line">        ssc.awaitTermination()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div></details>
运行上述代码后，依次在hadoop01、hadoop02、hadoop03服务器执行命令<code>zkServer.sh start</code>启动ZooKeeper集群；然后再依次在Kafka的根目录下执行命令<code>bin/kafka-server-start.sh config/server.properties</code>启动Kafka集群。</li>
</ul>
<ol>
<li>创建Topic, 指定消息的类别<details ><summary>创建来源主题和目标主题代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create \</span><br><span class="line">--topic kafka_direct0 \</span><br><span class="line">--partitions <span class="number">3</span> \</span><br><span class="line">--replication-factor <span class="number">1</span> \</span><br><span class="line">--zookeeper hadoop01:<span class="number">2181</span>,hadoop02:<span class="number">2181</span>,hadoop03:<span class="number">2181</span></span><br></pre></td></tr></table></figure></div></details></li>
<li>在hadoop01启动生产者服务，生产数据<details ><summary>启动生产者服务和消费者服务代码</summary><div class="fold-content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-<span class="built_in">list</span> hadoop01:<span class="number">9092</span> --topic kafka_direct0</span><br></pre></td></tr></table></figure></div></details></li>
<li>在生产者服务节点（hadoop01）输入hello kafka kafka语句，可在IDEA工具中查看控制台，可以看到控制台输出了{hello&#x3D;1, kafka&#x3D;2}信息</li>
</ol>

            </article>
            
                <div class="share">
                    <!--开启分享-->
<div class="share-component" data-disabled="google,twitter,facebook" data-description=""></div>


<script src="/js/share.min.js"></script>


                </div>    
            

            
            
                
<div class="comments">
    <div id="gitalk-container"></div>
        
<script src="/js/gitalk.js"></script>

        <script>
            var gitalk = new Gitalk({
                clientID: "",
                clientSecret: "",
                repo: '',
                owner: '',
                admin: [''],
                id: decodeURI('/posts/spark_07/'),
            })
        gitalk.render('gitalk-container')
        </script>
</div>

            

        </div>
        <div class="column one-fourth">
            
                
                


<h3>Post Directory</h3>

<div id="post-directory-module">
	<section class="post-directory">
		<p><strong class="toc-title">文章目录</strong></p>
		<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Streaming%E5%BC%80%E5%8F%91%E5%8D%95%E8%AF%8D%E8%AE%A1%E6%95%B0%E5%BA%94%E7%94%A8"><span class="toc-text">Kafka Streaming开发单词计数应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%B7%BB%E5%8A%A0%E4%BE%9D%E8%B5%96"><span class="toc-text">1. 添加依赖</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BC%96%E5%86%99%E4%BB%A3%E7%A0%81"><span class="toc-text">2. 编写代码</span></a></li></ol></li></ol>
	</section>
</div>
            
        </div>
    </div>
</section>

<footer class="container">
    <div class="site-footer" role="contentinfo">
        <div class="copyright left mobile-block">
                © 2016
                <span title="yumemor">yumemor</span>
                <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a>
        </div>

        <ul class="site-footer-links right mobile-hidden">
            <li>
                <a href="javascript:window.scrollTo(0,0)" >TOP</a>
            </li>
        </ul>

        <a href="https://github.com/yumemor/hexo-theme-primer" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <ul class="site-footer-links mobile-hidden">
            
                  
                  <li>
                    <a href="/"  title="Home">Home</a>
                  </li>
            
                  
                  <li>
                    <a href="/categories/"  title="Category">Category</a>
                  </li>
            
                  
                  <li>
                    <a href="/open-source/"  title="Open-Source">Open-Source</a>
                  </li>
            
                  
                  <li>
                    <a href="/message/"  title="Message">Message</a>
                  </li>
            
            <li>
                <a href="/atom.xml">
                    <span class="octicon octicon-rss" style="color:orange;"></span>
                </a>
            </li>
        </ul>
    </div>
</footer>

		
<script src="/js/geopattern.js"></script>

		
<script src="/js/highlight.pack.js"></script>

		
<script src="/lib/fancybox/jquery.fancybox-1.3.4.pack.js"></script>


		
			
<script src="/js/toc.js"></script>

		

		
<script src="/js/index.js"></script>


		 
<script src="/js/popular_repo.js"></script>
 

	</body>
</html>