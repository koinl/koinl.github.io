<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8 no-js"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9 no-js"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <title>第4章  Spark SQL结构化数据文件处理 | 锦鲤未离</title>

  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

  <meta name="description" content="本章目的在于如何使用Spark SQL模块来处理结构化数据，结构化数据即以关系型数据库表形式管理的数据。">
<meta property="og:type" content="article">
<meta property="og:title" content="第4章  Spark SQL结构化数据文件处理">
<meta property="og:url" content="http://example.com/posts/spark_04/index.html">
<meta property="og:site_name" content="锦鲤未离">
<meta property="og:description" content="本章目的在于如何使用Spark SQL模块来处理结构化数据，结构化数据即以关系型数据库表形式管理的数据。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2023-03-31T03:48:40.204Z">
<meta property="article:modified_time" content="2023-04-01T14:09:52.875Z">
<meta property="article:author" content="Koi_NL">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="锦鲤未离" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
    
  <meta content="{{ title }}" name="description">
  <meta content="{{ title }}" name="keywords">
  <meta content="{{ title }}" name="author">

  <link href="http://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700|PT+Sans+Narrow|Source+Sans+Pro:200,300,400,600,700,900&amp;subset=all" rel="stylesheet" type="text/css">

  <!-- Global styles START -->   
  
<link rel="stylesheet" href="/metronic/assets/plugins/font-awesome/css/font-awesome.min.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/bootstrap/css/bootstrap.min.css">

  <!-- Global styles END --> 
   
  <!-- Page level plugin styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/animate.css">

  
<link rel="stylesheet" href="/metronic/assets/plugins/owl.carousel/assets/owl.carousel.css">

  <!-- Page level plugin styles END -->

  <!-- Theme styles START -->
  
<link rel="stylesheet" href="/metronic/assets/pages/css/components.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/slider.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style.css">

  
<link rel="stylesheet" href="/metronic/assets/pages/css/portfolio.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/style-responsive.css">

  
<link rel="stylesheet" href="/metronic/assets/corporate/css/themes/red.css">

  
<link rel="stylesheet" href="/css/theme-styles.css">

  <!-- Theme styles END -->
<meta name="generator" content="Hexo 6.1.0"></head>

<body class="corporate">
  <!-- BEGIN TOP BAR -->
<div class="pre-header">
  <div class="container">
    <div class="row">
      <!-- BEGIN TOP BAR LEFT PART -->
      <div class="col-md-6 col-sm-6 col-xs-9 additional-shop-info">
	<ul class="list-unstyled list-inline">
	  <li><i class="fa fa-phone"></i><span>716-472-4484</span></li>
	  <li><i class="fa fa-envelope-o"></i><span>ptsteadman@gmail.com</span></li>
	</ul>
      </div>
      <!-- END TOP BAR LEFT PART -->
      <!-- BEGIN TOP BAR MENU -->
      <div class="col-md-6 col-sm-6 col-xs-3 additional-nav">
	<ul class="list-unstyled list-inline pull-right">
	  <li><a href="/login">Log In</a></li>
	</ul>
      </div>
      <!-- END TOP BAR MENU -->
    </div>
  </div>        
</div>
<!-- END TOP BAR -->
<!-- BEGIN HEADER -->
<div class="header">
  <div class="container">
    <!--<a class="site-logo" href="/" id="logo">锦鲤未离</a>-->

    <a class="site-logo" href="/">
      <img src="/metronic/assets/corporate/img/logos/logo-corp-red.png" alt="Metronic FrontEnd">
    </a>

    <a href="javascript:void(0);" class="mobi-toggler"><i class="fa fa-bars"></i></a>

    <!-- BEGIN NAVIGATION -->
    <div class="header-navigation pull-right font-transform-inherit">
      <ul>
	
	<li class="">
	  <a  href="/">Home</a>
	</li>
	
	<li class="">
	  <a  href="/projects/">Projects</a>
	</li>
	
	<li class="">
	  <a  href="/archives/">Blog</a>
	</li>
	
	<li class="">
	  <a  href="/contact/">Contact</a>
	</li>
	
	<li class="">
	  <a  href="/about/">About</a>
	</li>
	
	<!-- BEGIN TOP SEARCH -->
	<li class="menu-search">
	  <span class="sep"></span>
	  <i class="fa fa-search search-btn"></i>
	  <div class="search-box">
	    <form action="#">
	      <div class="input-group">
		<input type="text" placeholder="Search" class="form-control st-default-search-input">
		<span class="input-group-btn">
		  <button class="btn btn-primary" type="submit">Search</button>
		</span>
	      </div>
	    </form>
	  </div> 
	</li>
	<!-- END TOP SEARCH -->
      </ul>
    </div>
    <!-- END NAVIGATION -->
  </div>
</div>
<!-- Header END -->

  <div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li><a href="/archives/">Blog</a></li>
    <li class="active">Post</li>
  </ul>
  <section id="main">
    
    <h2 itemprop="name">
      <a class="article-title" href="/posts/spark_04/">第4章  Spark SQL结构化数据文件处理</a>
    </h2>


    <div class="row">
<div class="col-md-9 col-sm-9 blog-posts">
<article id="post-Spark/第4章  Spark SQL结构化数据文件处理" class="article article-type-post blog-item" itemscope itemprop="blogPost">
  <div class="article-meta">
  </div>
  <div class="article-inner">
    
    
    <header class="article-header">
      <ul class="blog-info">
	<li><i class="fa fa-user"></i> Anonymous</li>
	<li><i class="fa fa-calendar"></i>
	  <time datetime="2023-03-31T03:48:40.204Z" itemprop="datePublished">2023/03/31</time>

	</li>
	<li class="hidden-xs"><i class="fa fa-comments"></i>
	  <a href="http://example.com/posts/spark_04/#disqus_thread" class="article-comment-link">Comments</a>
	</li>
	<li class="hidden-xs"><i class="fa fa-tags"></i> 
	  

	</li>
      </ul>
      
  <div class="article-category">
    
    Category: 
    
    Categories:
    <a class="article-category-link" href="/categories/spark/">spark</a>
  </div>
  <br>


    </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本章目的在于如何使用Spark SQL模块来处理结构化数据，结构化数据即以<strong>关系型数据库表</strong>形式管理的数据。</p>
<span id="more"></span>

<p>首先，本章讲解在Linux系统下对结构化数据的处理。Spark SQL模块让用户可以通过<strong>SQL</strong>、<strong>DataFrame API</strong> 和 **DataSet API **三种方式来实现对结构化数据的处理。<br>在Spark-Shell操作下，RDD很容易就能转换成为DataFrame。那么在Windows系统下呢？又该如何使RDD转换成为DataFrame？</p>
<p>启动Spark-Shell的命令如下：<code>$ spark-shell --master local[2]</code>；如不能正常运行，可跳转到spark安装目录，使用命令 <code>$ bin/spark-shell</code> 启动Spark-shell。</p>
<details ><summary>文件：no4-createDataFrame.txt，该文件用于本章例子</summary><div class="fold-content"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将要用到的文件no4-createDataFrame.txt</span></span><br><span class="line">[root@hadoop01 ~]# hdfs dfs -cat /sparktest/data/no4-createDataFrame.txt</span><br><span class="line">zhangsan 20</span><br><span class="line">lisi 29</span><br><span class="line">wangwu 25</span><br><span class="line">zhaoliu 30</span><br><span class="line">tianqi 35</span><br><span class="line">jerry 40</span><br></pre></td></tr></table></figure></div></details>

<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><h3 id="DataFrame的创建"><a href="#DataFrame的创建" class="headerlink" title="DataFrame的创建"></a>DataFrame的创建</h3><p>创建DataFrame的方式是从一个已经存在的RDD调用toDF()方法进行转换，得到DataFrame；或者通过Spark读取数据源直接创建。<br>这里提供两种成员函数printSchema()和show()，作用分别为打印当前对象的Schema元数据信息和结果数据。</p>
<details ><summary>创建DataFrame的两种方式及部分成员函数</summary><div class="fold-content"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 通过文件直接创建DataFrame。除了读取text(.txt)文件，还可以读取csv、json、parquet等 | 创建方式1</span><br><span class="line">scala&gt; val personDF=spark.read.text(&quot;/sparktest/data/no4-createDataFrame.txt&quot;)</span><br><span class="line">personDF: org.apache.spark.sql.DataFrame = [value: string]</span><br><span class="line"></span><br><span class="line"># 打印当前对象的Schema元数据信息：String数据类型，且可为空。</span><br><span class="line">scala&gt; personDF.printSchema()</span><br><span class="line">root</span><br><span class="line"> |-- value: string (nullable = true)</span><br><span class="line"></span><br><span class="line"># 打印当前DataFrame的结果数据</span><br><span class="line">scala&gt; personDF.show()</span><br><span class="line">+-----------+       </span><br><span class="line">|      value    |</span><br><span class="line">+-----------+</span><br><span class="line">|zhangsan 20|</span><br><span class="line">|    lisi 29|</span><br><span class="line">|  wangwu 25|</span><br><span class="line">| zhaoliu 30|</span><br><span class="line">|  tianqi 35|</span><br><span class="line">|   jerry 40|</span><br><span class="line">+-----------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 从已经存在的RDD进行转换得到DataFrame，首先获取数据</span><br><span class="line"># 第一步</span><br><span class="line">scala&gt; case class Person(name:String,age:Int)</span><br><span class="line">defined class Person</span><br><span class="line"># 以上三步可直接写成：</span><br><span class="line">scala&gt; val pDF=sc.textFile(&quot;/sparktest/data/no4-createDataFrame.txt&quot;).map(_.split(&quot; &quot;)).map(x =&gt; Person(x(0),x(1).toInt)).toDF()</span><br><span class="line">scala&gt; pDF.show</span><br><span class="line">+--------+---+      </span><br><span class="line">|    name|age|</span><br><span class="line">+--------+---+</span><br><span class="line">|zhangsan| 20|</span><br><span class="line">|    lisi| 29|</span><br><span class="line">|  wangwu| 25|</span><br><span class="line">| zhaoliu| 30|</span><br><span class="line">|  tianqi| 35|</span><br><span class="line">|   jerry| 40|</span><br><span class="line">+--------+---+</span><br></pre></td></tr></table></figure></div></details>

<h3 id="DataFrame的常用操作"><a href="#DataFrame的常用操作" class="headerlink" title="DataFrame的常用操作"></a>DataFrame的常用操作</h3><p>DataFrame提供了两种语法风格，分别为DSL风格操作和SQL风格操作。对应的就是DataFrame API 、SQL两种方式。<br>DSL风格</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#查看name 字段的数据，PersonDF会随变量名的变化而变化。</span><br><span class="line">#以下五种方式可同义替代。但第四种方法不推荐！原因是因为某些代码可能不支持！</span><br><span class="line">pDF.select(pDF.col(&quot;name&quot;),pDF.col(&quot;age&quot;)).show</span><br><span class="line">pDF.select(pDF(&quot;name&quot;),pDF(&quot;age&quot;)).show</span><br><span class="line">pDF.select(col(&quot;name&quot;),col(&quot;age&quot;)).show</span><br><span class="line">pDF.select(&quot;name&quot;,&quot;age&quot;).show</span><br><span class="line"># pDF.select(&quot;name&quot;,&quot;age&quot;+1).show 不可运行！</span><br><span class="line"># 但其他四个可运行！例如“$&quot;age&quot;+1”、“col(&quot;age&quot;)+1”</span><br><span class="line"># 请注意可以通过as来重命名列名</span><br><span class="line">pDF.select($&quot;name&quot;,($&quot;age&quot;+1).as(&quot;new_age&quot;)).show</span><br><span class="line"></span><br><span class="line">#条件过滤（对应Where语句）</span><br><span class="line">pDF.filter($&quot;age&quot; &gt;30).show</span><br><span class="line"></span><br><span class="line">#分组（对应Group By语句）</span><br><span class="line">pDF.groupBy(&quot;age&quot;).count().show</span><br><span class="line"></span><br><span class="line">#排序（对应Order By语句）</span><br><span class="line">pDF.sort($&quot;age&quot;.desc).show</span><br></pre></td></tr></table></figure>
<h4 id="SQL风格操作"><a href="#SQL风格操作" class="headerlink" title="SQL风格操作"></a>SQL风格操作</h4><p>将DataFrame注册成一个临时表就可以进行SQL风格操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; pDF.registerTempTable(&quot;t_koinl&quot;)</span><br><span class="line">scala&gt; spark.sql(&quot;select name, age + 1 from t_koinl&quot;).show</span><br></pre></td></tr></table></figure>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><h2 id="RDD转换为DataFrame"><a href="#RDD转换为DataFrame" class="headerlink" title="RDD转换为DataFrame"></a>RDD转换为DataFrame</h2><p>在上文中，有说明在Spark-shell中如何将RDD转换为DataFrame，在本小节中，来说明如何在Windows系统下开发Scala代码。</p>
<p>一般情况下，可以使用两种方法来实现。第一种方法是利用反射机制来推断包含特定类型对象的Schema。当<strong>case类不能提前定义，即未知数据结构</strong>时，应通过编程接口构造一个Schema，并将其应用在已知的RDD数据中。 </p>
<h2 id="Spark-SQL操作数据源"><a href="#Spark-SQL操作数据源" class="headerlink" title="Spark SQL操作数据源"></a>Spark SQL操作数据源</h2><h3 id="操作MySQL"><a href="#操作MySQL" class="headerlink" title="操作MySQL"></a>操作MySQL</h3><h4 id="读取MySQL种数据"><a href="#读取MySQL种数据" class="headerlink" title="读取MySQL种数据"></a>读取MySQL种数据</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Properties</span><br><span class="line">import org.apache.spark.sql.&#123;DataFrame, SaveMode,SparkSession&#125;</span><br><span class="line"> </span><br><span class="line">object sparkSqlMysql &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //创建sparkSession对象</span><br><span class="line">    val spark: SparkSession = SparkSession.builder()</span><br><span class="line">      .appName(&quot;sparkSqlMysql&quot;)</span><br><span class="line">      .master(&quot;local[2]&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    //创建Properties对象，配置连接mysql的用户名和密码</span><br><span class="line">    val prop: prop =new Properties()</span><br><span class="line">    prop.setProperty(&quot;user&quot;,&quot;root&quot;)</span><br><span class="line">    prop.setProperty(&quot;password&quot;,&quot;123456&quot;)</span><br><span class="line">    //从数据库里读取数据</span><br><span class="line">    val mysqlDF: DataFrame = spark.read.jdbc(&quot;jdbc:mysql://127.0.0.1:3306/spark&quot;, &quot;person&quot;, prop)</span><br><span class="line">    //显示Mysql中表数据</span><br><span class="line">    mysqlDF.show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="写入数据到MySQL"><a href="#写入数据到MySQL" class="headerlink" title="写入数据到MySQL"></a>写入数据到MySQL</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Properties</span><br><span class="line">import org.apache.spark.rdd.RDD</span><br><span class="line">import org.apache.spark.sql.&#123;DataFrame, SaveMode,SparkSession&#125;</span><br><span class="line"> case class Person(id:Int,name:String,age:Int)</span><br><span class="line"></span><br><span class="line">object sparkSqlMysql &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //创建sparkSession对象</span><br><span class="line">    val spark: SparkSession = SparkSession.builder()</span><br><span class="line">      .appName(&quot;sparkSqlMysql&quot;)</span><br><span class="line">      .master(&quot;local[2]&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    val sc = spark.sparkContext.parallelize(Array(&quot;3,wangwu,22&quot;,&quot;4,zhaoliu,26&quot;))</span><br><span class="line">    //切分读取数据</span><br><span class="line">    val data: RDD[Array[String]] = sc.map(_.split(&quot;,&quot;))</span><br><span class="line">    //RDD关联Person</span><br><span class="line">    val personRdd: RDD[Person] = data.map(x =&gt; Person(x(0)。toInt,x(1), x(2).toLong))</span><br><span class="line">    //导入隐式转换</span><br><span class="line">    import spark.implicits._</span><br><span class="line">    //将RDD转换成DataFrame</span><br><span class="line">    val personDF: DataFrame = personRdd.toDF()</span><br><span class="line">    //创建Properties对象，配置连接mysql的用户名和密码</span><br><span class="line">    val prop =new Properties()</span><br><span class="line">    prop.setProperty(&quot;user&quot;,&quot;root&quot;)</span><br><span class="line">    prop.setProperty(&quot;password&quot;,&quot;123456&quot;)</span><br><span class="line">    //将personDF写入MySQL</span><br><span class="line"> </span><br><span class="line">    personDF.write.mode(SaveMode.Append).jdbc(&quot;jdbc:mysql://127.0.0.1:3306/spark?useUnicode=true&amp;characterEncoding=utf8&quot;,&quot;person&quot;,prop)</span><br><span class="line">    personDF.show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="操作Hive"><a href="#操作Hive" class="headerlink" title="操作Hive"></a>操作Hive</h3>
      
    </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/posts/spark_05/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          第5章  HBase 分布式数据库
        
      </div>
    </a>
  
  
    <a href="/posts/spark_01/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">第1章  Scala语言基础.</div>
    </a>
  
</nav>

  
  <br>
</article>




</div>
<div class="col-md-3 col-sm-3 blog-sidebar">
  <!-- CATEGORIES START -->
<h2 class="no-top-space">Categories</h2>

<div class="widget-wrap">
  <div class="widget">
    <ul class="nav sidebar-categories margin-bottom-40">
      
	<li>
	  <a href="/categories/%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87/">电子设备 (2)</a>
	</li>
      
	<li>
	  <a href="/categories/Hadoop/">Hadoop (4)</a>
	</li>
      
	<li>
	  <a href="/categories/Data-Processing-and-Analysing/">Data-Processing-and-Analysing (4)</a>
	</li>
      
	<li>
	  <a href="/categories/Applied-Statistics/">Applied Statistics (1)</a>
	</li>
      
	<li>
	  <a href="/categories/%E6%B5%8B%E8%AF%95%E5%8C%BA/">测试区 (3)</a>
	</li>
      
	<li>
	  <a href="/categories/Data-Mining/">Data-Mining (1)</a>
	</li>
      
	<li>
	  <a href="/categories/MATLAB/">MATLAB (5)</a>
	</li>
      
	<li>
	  <a href="/categories/java/">java (7)</a>
	</li>
      
	<li>
	  <a href="/categories/Linux/">Linux (9)</a>
	</li>
      
	<li>
	  <a href="/categories/Data-Structure-and-Algorithm/">Data Structure and Algorithm (5)</a>
	</li>
      
	<li>
	  <a href="/categories/Python/">Python (13)</a>
	</li>
      
	<li>
	  <a href="/categories/SqlServer/">SqlServer (17)</a>
	</li>
      
	<li>
	  <a href="/categories/%E8%80%83%E8%AF%95/">考试 (1)</a>
	</li>
      
	<li>
	  <a href="/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/">时间序列分析 (1)</a>
	</li>
      
	<li>
	  <a href="/categories/spark/">spark (7)</a>
	</li>
      
	<li>
	  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">深度卷积神经网络 (1)</a>
	</li>
      
    </ul>
  </div>
</div>


<!-- CATEGORIES END -->

<!-- BEGIN BLOG TAGS -->
<div class="blog-tags margin-bottom-20">
  <h2>Tags</h2>
  

</div>
<!-- END BLOG TAGS -->


<!-- BEGIN FEATURED POSTS -->                            
<h2>Featured Posts</h2>
<div class="recent-news margin-bottom-10">
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</div>
<!-- END FEATURED POSTS -->                            

</div>
</div>

  </section>
</div>

    <!-- BEGIN PRE-FOOTER -->
    <div class="pre-footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN BOTTOM ABOUT BLOCK -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>About Us</h2>
            <p>Computer Lab is a software development and marketing company based in Brooklyn, New York. <br><br> Computer Lab was founded in 2015, and is focused on so on and so forth.</p>
          </div>
          <!-- END BOTTOM ABOUT BLOCK -->

          <!-- BEGIN BOTTOM CONTACTS -->
          <div class="col-md-4 col-sm-6 pre-footer-col">
            <h2>Contact</h2>
            <address class="margin-bottom-40">
              140 Metropolitan Avenue<br>
              5th Floor<br>
              Brooklyn, NY 11249<br>
              Phone: 716-472-4484<br>
              Email: <a href="mailto:ptsteadman@gmail.com">ptsteadman@gmail.com</a><br>
            </address>
          </div>
          <!-- END BOTTOM CONTACTS -->

	
          <!-- BEGIN TWITTER BLOCK --> 
          <div class="col-md-4 col-sm-6 pre-footer-col">

	  <a data-tweet-limit="1" class="twitter-timeline" data-theme="dark"
	  target="_blank" rel="noopener" href="https://twitter.com/computerlab_">Tweets by @computerlab_</a>

	  <script>!function(d,s,id){var
	  js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>

          </div>
          <!-- END TWITTER BLOCK -->
	
        </div>
      </div>
    </div>
    <!-- END PRE-FOOTER -->

    <!-- BEGIN FOOTER -->
    <div class="footer">
      <div class="container">
        <div class="row">
          <!-- BEGIN COPYRIGHT -->
          <div class="col-md-6 col-sm-6 padding-top-10">
                  &copy; 2023 锦鲤未离<br>
 <a href="javascript:;">Privacy Policy</a> | <a href="javascript:;">Terms of Service</a>
          </div>
          <!-- END COPYRIGHT -->
	  <!-- BEGIN SOCIAL -->
<div class="col-md-6 col-sm-6">
  <ul class="social-footer list-unstyled list-inline pull-right">
    
      <li><a target="_blank" rel="noopener" href="https://github.com/ptsteadman"><i class="fa fa-github"></i></a></li>
    
      <li><a target="_blank" rel="noopener" href="https://twitter.com/ptsteadman"><i class="fa fa-twitter"></i></a></li>
    
      <li><a target="_blank" rel="noopener" href="https://www.facebook.com/ptsteadman"><i class="fa fa-facebook"></i></a></li>
    
      <li><a href="/atom.xml"><i class="fa fa-rss"></i></a></li>
    
      <li><a target="_blank" rel="noopener" href="https://linkedin.com/in/ptsteadman"><i class="fa fa-linkedin"></i></a></li>
    
      <li><a target="_blank" rel="noopener" href="http://stackoverflow.com/users/2480493/patrick-steadman"><i class="fa fa-stackoverflow"></i></a></li>
    
  </ul>  
</div>
<!-- END SOCIAL -->

        </div>
      </div>
    </div>
    <!-- END FOOTER -->

  <!-- BEGIN CORE PLUGINS (REQUIRED FOR ALL PAGES) -->
<!--[if lt IE 9]>

<script src="/metronic/assets/plugins/respond.min.js"></script>

<![endif]--> 

<script src="/metronic/assets/plugins/jquery.min.js"></script>


<script src="/metronic/assets/plugins/jquery-migrate.min.js"></script>


<script src="/metronic/assets/plugins/bootstrap/js/bootstrap.min.js"></script>


<script src="/metronic/assets/corporate/scripts/back-to-top.js"></script>


<script src="/metronic/assets/plugins/owl.carousel/owl.carousel.min.js"></script>


<script src="/metronic/assets/corporate/scripts/layout.js"></script>


<script src="/js/wow.min.js"></script>



  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<script type="text/javascript">
    jQuery(document).ready(function() {
        Layout.init();    
        Layout.initOWL();
        Layout.initTwitter();
        Layout.initFixHeaderWithPreHeader(); /* Switch On Header Fixing (only if you have pre-header) */
        Layout.initNavScrolling(); 
	new WOW().init();
    });
</script>
<!-- END CORE PLUGINS -->

<!-- BEGIN PAGE-SPECIFIC PLUGINS --> 







<!-- END PAGE-SPECIFIC PLUGINS --> 

<!-- BEGIN INTEGRATIONS -->





<!-- END INTEGRATIONS -->

</body>
</html>
