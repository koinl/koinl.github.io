<!doctype html>
<html>
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable"  content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no">
    
    
    <!--Simple SEO-->


<meta name="robots" content=all />
<meta name="google" content=all />
<meta name="googlebot" content=all />
<meta name="verify" content=all />
    <!--Title-->

<title>第一章  分布式文件系统（HDFS）概述 | 锦鲤未离</title>

<link rel="alternate" href="/atom.xml" title="锦鲤未离" type="application/atom+xml">


<link rel="icon" href="/favicon.ico">

    

<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/css/pages/post.css">
<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/thirdParty/highlight/github.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">


    <!--script-->



<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

<script>
  var admin = "GeekaholicLin";
  admin = admin.split(",");
  var gitalk = new Gitalk({
    clientID: "xxxxx",
    clientSecret: "xxxxx",
    repo: "geekaholiclin.github.io",
    owner: "GeekaholicLin",
    admin: admin,
    id: decodeURIComponent(location.pathname),
    distractionFreeMode: false
  })

</script>

    
    
<meta name="generator" content="Hexo 6.1.0"></head>

<body id="normal">
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<style>
    header{ top: 71px; position: absolute!important;}
    #container{padding-top: 151px!important;}
</style>
<div style="position:fixed;z-index:9999;left:0;top:0;width:100%;height:70px;background-color:#e0e0e0;color:#396CA5;border-bottom:1px solid #cecece;text-align:center;line-height:70px;white-space: nowrap;overflow: hidden;text-overflow: ellipsis">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<div id="wrap">
    <header  style="position: absolute;" >
    <div id="site-meta">
        <a href="/" id="logo">
            <h1 class="title">锦鲤未离</h1>
        </a>
        
        <h2 class="subtitle">KoiNL</h2>
        
    </div>
    <ul id="nav">
        
            <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
        
            <li><a href="/atom.xml"><i class="fa fa-rss"></i>RSS</a></li>
        
        <li id="search"><a href="javascript:void(0)"><i class="fa fa-search"></i>搜索</a></li>
    </ul>
</header>

    <div id="container">
        
<ul id="sidebar">
    
    
<li class="widget notification">
    <i class="fa fa-bell-o"></i>
    <div>
        
<p>主题ylion v0.0.0版本即将上线，敬请期待~！
主题作者：<a href="https://github.com/GeekaholicLin"
title="fork me" target="_blank">Geekaholic</a></p>
    </div>
</li>

    
    
<li class="widget widget-normal category">
    <h3 class="fa fa-th widget-title">分类</h3>
    <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Applied-Statistics/"><i class="fa" aria-hidden="true">Applied Statistics</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure-and-Algorithm/"><i class="fa" aria-hidden="true">Data Structure and Algorithm</i></a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Mining/"><i class="fa" aria-hidden="true">Data-Mining</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Processing-and-Analysing/"><i class="fa" aria-hidden="true">Data-Processing-and-Analysing</i></a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/"><i class="fa" aria-hidden="true">Hadoop</i></a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/"><i class="fa" aria-hidden="true">Linux</i></a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATLAB/"><i class="fa" aria-hidden="true">MATLAB</i></a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/"><i class="fa" aria-hidden="true">Python</i></a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SqlServer/"><i class="fa" aria-hidden="true">SqlServer</i></a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/"><i class="fa" aria-hidden="true">java</i></a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/"><i class="fa" aria-hidden="true">spark</i></a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"><i class="fa" aria-hidden="true">时间序列分析</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B5%8B%E8%AF%95%E5%8C%BA/"><i class="fa" aria-hidden="true">测试区</i></a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa" aria-hidden="true">深度卷积神经网络</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87/"><i class="fa" aria-hidden="true">电子设备</i></a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%80%83%E8%AF%95/"><i class="fa" aria-hidden="true">考试</i></a><span class="category-list-count">1</span></li></ul>
</li>


    
    
<li class="widget widget-normal archive">
  <h3 class="fa fa-archive widget-title">归档</h3>
    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/"><i class="fa" aria-hidden="true">三月 2023</i></a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/"><i class="fa" aria-hidden="true">二月 2023</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/"><i class="fa" aria-hidden="true">十一月 2022</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/"><i class="fa" aria-hidden="true">十月 2022</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/"><i class="fa" aria-hidden="true">九月 2022</i></a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/"><i class="fa" aria-hidden="true">八月 2022</i></a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/"><i class="fa" aria-hidden="true">七月 2022</i></a><span class="archive-list-count">25</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/"><i class="fa" aria-hidden="true">六月 2022</i></a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/"><i class="fa" aria-hidden="true">五月 2022</i></a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/"><i class="fa" aria-hidden="true">四月 2022</i></a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/"><i class="fa" aria-hidden="true">三月 2022</i></a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/"><i class="fa" aria-hidden="true">二月 2022</i></a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/"><i class="fa" aria-hidden="true">一月 2022</i></a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1999/01/"><i class="fa" aria-hidden="true">一月 1999</i></a><span class="archive-list-count">2</span></li></ul>
</li>


    
    
<li class="widget widget-normal popular-posts" id="popular-posts">
    <h3 class="fa fa-thermometer-3 widget-title">热门文章</h3>
    <ul id="popular-content">
        <li class="load-first"><i class="fa fa-spinner fa-pulse"></i></li>
    </ul>
</li>

    
    

    
    
<li class="widget widget-normal friends-link">
    <h3 class="fa fa-globe widget-title">友链</h3><br/>

    
        <a href="http://geekaholiclin.github.io" class="fa" target="_blank">主题作者</a>

    

</li>

    
</ul>


        <div id="main">
    <article id="post">
        <div id="post-header">

            <h1 id="第一章  分布式文件系统（HDFS）概述">
                
                第一章  分布式文件系统（HDFS）概述
                
            </h1>
            <div class="article-meta">
    
    
    <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
        <span>Hadoop</span>
    </span>
    
    
    <span class="fa-wrap">
         <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
            null
            
        </span>
    </span>
    
    
    <span class="fa-wrap">
        <i class="fa fa-clock-o"></i>
        <span class="date-meta ">2022/09/07</span>
    </span>
    
    
    <span class="fa-wrap">
            <i class="fa fa-thermometer-three-quarters"></i>
        <span class="hits hits-meta " data-leadcloud-title="第一章  分布式文件系统（HDFS）概述"
              data-leadcloud-url="/posts/hadoop01/"><i class="fa fa-spinner fa-spin"></i></span>
    </span>
    
    
</div>

            
            
        </div>
        
        <div id="post-body">
            <p>HDFS 是一个支持海量数据存储的分布式文件系统，是存储大数据文件的重要载体。本章主要介绍了 HDFS 的体系结构、运行机制、工作流程和基本操作。</p>
<h2 id="一、HFDS-概述"><a href="#一、HFDS-概述" class="headerlink" title="一、HFDS 概述"></a>一、HFDS 概述</h2><h3 id="1-HDFS-的设计目标和不足"><a href="#1-HDFS-的设计目标和不足" class="headerlink" title="1. HDFS 的设计目标和不足"></a>1. HDFS 的设计目标和不足</h3><blockquote>
<p>设计目标：</p>
<ol>
<li>支持超大文件存储</li>
<li>采用一次写入多次读取（write-once-read-many）访问模型</li>
<li>具有故障检测和快速自动恢复功能</li>
<li>采用流式数据访问</li>
<li>支持移动计算</li>
</ol>
</blockquote>
<blockquote>
<p>不足：</p>
<ol>
<li>不适合处理低延迟数据访问</li>
<li>无法高效存储大量小文件</li>
<li>不支持多用户写入和任意修改文件</li>
</ol>
</blockquote>
<h3 id="2-HDFS-的体系结构"><a href="#2-HDFS-的体系结构" class="headerlink" title="2. HDFS 的体系结构"></a>2. HDFS 的体系结构</h3><p>HDFS 是一个<strong>主&#x2F;从（master&#x2F;slave）</strong>架构的系统，即一个 HDFS 集群由一个 <strong>NameNode</strong> 和若干 <strong>DataNode</strong> 组成。它俩也是 HDFS 的<strong>核心组件</strong>，其中，NameNode 被称为“<strong>元数据节点</strong>”、另一个被称为“<strong>数据节点</strong>”。</p>
<h4 id="3-数据块（block）"><a href="#3-数据块（block）" class="headerlink" title="3. 数据块（block）"></a>3. 数据块（block）</h4><p>磁盘数据块是磁盘读写的最小单位，也只能读写块整倍大小的数据。HDFS 的默认数据块大小为 <strong>128MB</strong>。</p>
<blockquote>
<p>通常为512B，那为什么设置这么大？<strong>数据块越大，寻址开销越小</strong>。当然，盲目过大也不行，MapReduce 中的 Map 一次只处理一个块的内容，<strong>过大会导致整体任务量变少</strong>，进而影响数据的<strong>并行</strong>处理速度。</p>
</blockquote>
<blockquote>
<p>优点：<br>可以存储任意大小的数据文件，只要物理切片就可以。<br>简化了存储系统的管理：元数据信息和文件数据信息分开管理。<br>有利于实现分布式文件系统的容错性：一个节点出故障，其他块读取副本。<br>有利于实现负载军和并提高集群可靠性：某个数据节点的剩余空间低于临界点，就将这个数据节点移动到其他的数据节点上；此外，数据块的副本被安排在不同的机架上，即使丢失某台机架，读取副本即可，大大提高了集群的可靠性。与此同时，Hadoop 的故障检测和快速自动回复功能就可以及时将这些块副本数量恢复到正常水平。</p>
</blockquote>
<h4 id="4-NameNode-和-SecondaryNameNode"><a href="#4-NameNode-和-SecondaryNameNode" class="headerlink" title="4. NameNode 和 SecondaryNameNode"></a>4. NameNode 和 SecondaryNameNode</h4><h5 id="1-元数据节点（NameNode）"><a href="#1-元数据节点（NameNode）" class="headerlink" title="1) 元数据节点（NameNode）"></a>1) 元数据节点（NameNode）</h5><p>管理 HDFS 文件系统的命名空间（namespace）。其实就是 HDFS 的目录结构，用户可以进行增删改重命名等 HDFS 文件。</p>
<blockquote>
<p>所存储的元数据信息：</p>
<ol>
<li>文件名、目录名与层次关系</li>
<li>文件目录的属主和权限</li>
<li>每个文件由哪些数据块组成</li>
<li>数据块到数据节点的映射信息</li>
</ol>
</blockquote>
<p>元数据信息被持久化的存到本地磁盘的两个文件中：<strong>fsimage（元数据镜像文件）</strong>和 <strong>edits（事务日志文件）</strong>。</p>
<p>元数据节点正常运行时，所有更新操作被写入 edits 文件中，如果直接写入元数据镜像文件，逐渐一段时间后，过大会导致系统运行速度变慢。即 edits 文件越来越大，不会对系统有明显影响，但是元数据节点的重启过程会越来越慢。</p>
<h5 id="2-SecondaryNameNode（辅助者-·-元数据节点）"><a href="#2-SecondaryNameNode（辅助者-·-元数据节点）" class="headerlink" title="2) SecondaryNameNode（辅助者 · 元数据节点）"></a>2) SecondaryNameNode（辅助者 · 元数据节点）</h5><p>解决掉 edits 文件过大的问题。是对 元数据镜像文件和事务日志文件进行定期合并。由于合并时需要消耗内存，因此通常这俩<strong>没在一个节点</strong>上面。</p>
<blockquote>
<p>优点：</p>
<ol>
<li>提升了集群性能，保存了元数据节点的元数据信息，一定程度上提高了元数据的安全性和可靠性。</li>
</ol>
</blockquote>
<h5 id="3-数据节点（DataNode）"><a href="#3-数据节点（DataNode）" class="headerlink" title="3) 数据节点（DataNode）"></a>3) 数据节点（DataNode）</h5><p>一个数据节点有多个数据块，每个数据块会在多个数据节点上存储副本，但一个数据节点只能有一个副本。</p>
<blockquote>
<p>作用：<br>负责向<strong>客户端</strong>或<strong>元数据节点</strong>提供数据的检索和读写服务，并通过<strong>心跳机制</strong>定期向元数据节点发送自己的块列表信息。<br>一般情况下，数据节点会从磁盘中读取数据块，但如果某个块被频繁访问，系统会将其存放在数据节点的内存中。</p>
</blockquote>
<h6 id="从现有集群里面动态增加一个数据节点，怎么破？"><a href="#从现有集群里面动态增加一个数据节点，怎么破？" class="headerlink" title="从现有集群里面动态增加一个数据节点，怎么破？"></a>从现有集群里面动态增加一个数据节点，怎么破？</h6><p>—索引眼：<em>增加数据节点<strong>增加一个数据节点</strong>增加一个DataNode<strong>增加DataNode</strong>hadoop04**Hadoop04</em>—</p>
<h2 id="二、数据错误与恢复"><a href="#二、数据错误与恢复" class="headerlink" title="二、数据错误与恢复"></a>二、数据错误与恢复</h2><p>HDFS 的主要目标有一条是“具有故障检测和快速自动恢复功能”，这就要求即使再出错的情况下也要保证数据存储的可靠性。常见的出错情况包括block 损坏、NameNode 和 DataNode 的错误。</p>
<h3 id="1-block-损坏处理"><a href="#1-block-损坏处理" class="headerlink" title="1. block 损坏处理"></a>1. block 损坏处理</h3><p><strong>网络传输错误</strong>和<strong>机器硬件故障</strong>等因素会造成数据损坏。<br>客户端在读取文件时会对每个读取的块进行校验，如果出错，就会读取其他数据节点上的数据块，并将错误块报告给元数据节点，元数据节点随后会重新复制。<br>此外，每一个数据节点都会开启一个<strong>块扫描进程</strong>，来定期验证块的正确性，不正确会报告给元数据节点进行处理。</p>
<h3 id="2-NameNode-和-DataNode-错误处理"><a href="#2-NameNode-和-DataNode-错误处理" class="headerlink" title="2. NameNode 和 DataNode 错误处理"></a>2. NameNode 和 DataNode 错误处理</h3><h4 id="1-NameNode-错误处理"><a href="#1-NameNode-错误处理" class="headerlink" title="1) NameNode 错误处理"></a>1) NameNode 错误处理</h4><p>NameNode 上保存了元数据信息，仅此一份独一无二，因此必须确保该安全。</p>
<blockquote>
<p>容错方式有以下三种：</p>
<ol>
<li>元数据信息持久化到本地磁盘并同步到 NFS 中，但会因网络带宽等原因造成元数据丢失。</li>
<li>运行 SecondaryNameNode。但由于该备份的元数据信息滞后于 NameNode，所以也会丢失掉部分的数据信息。</li>
<li>启用主备两个NameNode。</li>
</ol>
</blockquote>
<h2 id="三、HDFS的运行机制"><a href="#三、HDFS的运行机制" class="headerlink" title="三、HDFS的运行机制"></a>三、HDFS的运行机制</h2><h3 id="1-副本机制"><a href="#1-副本机制" class="headerlink" title="1. 副本机制"></a>1. 副本机制</h3><blockquote>
<p>作用：<br>为了维护爱与和平…咳咳串台了，再来！为了保证集群的容错性和可用性。</p>
</blockquote>
<h3 id="2-心跳机制"><a href="#2-心跳机制" class="headerlink" title="2. 心跳机制"></a>2. 心跳机制</h3><p>NameNode 启动后，会等待所有 DataNode 的“心跳”：DataNode 每隔一定间隔（默认三秒）主动向 NameNode 发送“心跳”，主动报告自己的状态信息。然后 NameNode 通过心跳向 DataNode 下达命令。<br>如果长时间未收到，则可以证明该 DataNode 宕机，然后检查该 DataNode 上的块副本信息并备份到其他的 DataNode 上。<br>对了，DataNode 会给主备主数据节点都会发送“心跳”。</p>
<h3 id="3-副本放置与机架感应策略"><a href="#3-副本放置与机架感应策略" class="headerlink" title="3. 副本放置与机架感应策略"></a>3. 副本放置与机架感应策略</h3><h4 id="1-副本放置"><a href="#1-副本放置" class="headerlink" title="1) 副本放置"></a>1) 副本放置</h4><p>一个集群中多个机架，每个机架上多个数据节点，每个数据节点保存多个块副本。另外，元数据节点的元数据存储着每个数据节点所属的机架 ID。那么，如何分配文件的块副本到集群中的数据节点上面呢？</p>
<p>默认下，副本的配置数为 3，其中，有两个被放在同一机架的不同数据节点上面，另外一个被另一个机架上。</p>
<blockquote>
<p>一般情况下，3 个足矣。若大于等于 3，则之后的副本可以随意放置。避免一个机架有太多同意副本即可。</p>
</blockquote>
<h4 id="2-机架感应（rack-aware）"><a href="#2-机架感应（rack-aware）" class="headerlink" title="2) 机架感应（rack-aware）"></a>2) 机架感应（rack-aware）</h4><p>由于副本的存放位置会影响 HDFS 的可靠性和性能，HDFS 采用了一种机架感知策略来提高数据的可靠性，并提高网络带宽的利用率。<br>这样一来，即使一个机架发生故障，由于其他机架上的副本仍然可用，不会影响数据的可靠性。另外，当读取数据时，应用程序可用在多个机架上同时读取，大大提高数据的读取速度。</p>
<h3 id="4-联邦（Federation）机制"><a href="#4-联邦（Federation）机制" class="headerlink" title="4. 联邦（Federation）机制"></a>4. 联邦（Federation）机制</h3><p>每个文件的元数据信息都需要保存到 NameNode 的内存中，于是便有了联邦机制。</p>
<blockquote>
<p>作用：<br>集群横向扩展的方式解决 NameNode 的瓶颈问题，即<strong>增加元数据节点的数量</strong>。<br>由于 Hadoop 针对海量数据进行存储管理，并采用了数据冗余存储方式，所以<strong>磁盘I&#x2F;O才是集群的《主要瓶颈》。</strong></p>
</blockquote>
<p>在联邦机制中，每个 NameNode 分别管理文件系统命名口径的一部分（命名空间卷）。各卷中分别存储了命名空间的元数据和文件数据块的块池。同时，各卷相互独立互不影响互不通信。此外，集群中的所有 DataNode 都必须注册到各个 NameNode。</p>
<p>不过，没有解决掉单点故障问题，若某一个 NameNode 失效，仍无法恢复无法访问。</p>
<h3 id="5-HA（7-24小时不中断服务）-机制"><a href="#5-HA（7-24小时不中断服务）-机制" class="headerlink" title="5. HA（7*24小时不中断服务） 机制"></a>5. HA（7*24小时不中断服务） 机制</h3><p>所谓HA，即高可用（7*24小时不中断服务）。实现高可用最关键的是消除单点故障。<br>方式：允许运行主备两个 NameNode，当 NameNode 节点发生故障时，可以快速启用备用的 NameNode，以确保集群正常运行。</p>
<p>备主数据节点和主主数据节点始终同步（元数据信息一致），它们之间通过 JournalNode 守护进程进行通信。</p>
<h3 id="6-安全模式"><a href="#6-安全模式" class="headerlink" title="6. 安全模式"></a>6. 安全模式</h3><p>启用后，就进入了安全模式。该模式下，主数据节点会检查块的完整性。此外，它还是一种只读模式。<br>正常情况下，NameNode启动（额外延迟30s）就会退出安全模式，但是如果DataNode 丢失的数据块超过设定的值，集群就会一直处于安全模式。</p>
<p>两件事</p>
<ol>
<li>等待每个数据节点的心跳，判断是否宕机，然后NameNode 将 DataNode 所发送的 block 报告与其元数据进行对比，以判断数据块是否正常。</li>
<li>在内存中加载 fsimage，然后将 fsimage 和edits 合并成新的 fsimage，并创建一个新的 edits。合并完成后删除旧的 fsimage 和 edits，并将新的俩重命名。<h3 id="7-垃圾回收"><a href="#7-垃圾回收" class="headerlink" title="7. 垃圾回收"></a>7. 垃圾回收</h3>没有任何利用价值的块副本被认为是垃圾：若一个文件被删除，那么备份的该文件副本也就没有用。<br>删除不会直接删除，会移动到回收站。<h2 id="四、HDFS-的工作流程"><a href="#四、HDFS-的工作流程" class="headerlink" title="四、HDFS 的工作流程"></a>四、HDFS 的工作流程</h2>在 Hadoop 集群中，<strong>客户端</strong>与<strong>元数据节点</strong>之间的通信、<strong>元数据节点</strong>与<strong>数据节点</strong>之间的通信、<strong>数据节点</strong>相互之间的通信、都是基于 <strong>RPC（远程过程调用）</strong>机制的。</li>
</ol>
<h3 id="1-启动流程"><a href="#1-启动流程" class="headerlink" title="1. 启动流程"></a>1. 启动流程</h3><p>在 HDFS 的启动过程中，需要启动 NameNode 和DataNode。<br>启动时，会先进入安全模式。<br>数据节点启动时，会开启一个 DataBlockScanner 进程来扫描 block，并且由该进程定期向各个 NameNode 发送“心跳”。</p>
<h3 id="2-读流程"><a href="#2-读流程" class="headerlink" title="2. 读流程"></a>2. 读流程</h3><p>Client 读取时，首先会访问 NameNode 以确认是否可以读取。是，则 Client 获得文件的 block 和 DataNode 信息，然后执行 HDFS 的读操作来获取数据。在读取数据结束后，需要关闭文件输入流。</p>
<h3 id="3-写流程"><a href="#3-写流程" class="headerlink" title="3. 写流程"></a>3. 写流程</h3><p>Client 将数据预备写入到 HDFS 文件时，首先会访问 NameNode 确认写入的权限和文件是否存在（存在是否覆盖）。是，Client 在 NameNode 上创建写入文件的元数据信息，并返回可存储数据的 block 和 DataNode 信息，然后根据返回信息执行副本复制过程。写入结束后，需要关闭文件输出流。</p>
<h3 id="4-删除流程"><a href="#4-删除流程" class="headerlink" title="4. 删除流程"></a>4. 删除流程</h3><h4 id="1-使用-HDFS-命令删除文件"><a href="#1-使用-HDFS-命令删除文件" class="headerlink" title="1) 使用 HDFS 命令删除文件"></a>1) 使用 HDFS 命令删除文件</h4><p>root 用户的回收站目录为 <code>hdfs://hadoop0:9000/user/root/.Trash</code>。<br>当用户使用 HDFS 命令执行删除操作后，系统会将需要删除的文件移动到回收站内的“&#x2F;Current”下。例如，root用户删除了“koinl01.txt”文件，就可以在 <code>hdfs://hadoop0:9000/user/root/.Trash/Current/koinl01.txt</code> 找到。<br>回收站也是有时间周期滴。</p>
<h4 id="2-使用-Java-API-删除文件"><a href="#2-使用-Java-API-删除文件" class="headerlink" title="2) 使用 Java API 删除文件"></a>2) 使用 Java API 删除文件</h4><p>需要有一段延迟时间，才可以真正删除掉。</p>
<h2 id="五、HDFS-的基本操作"><a href="#五、HDFS-的基本操作" class="headerlink" title="五、HDFS 的基本操作"></a>五、HDFS 的基本操作</h2><p>基本操作包括：创建文件、移动文件、查看文件目录、读取文件等</p>
<h3 id="1-HDFS-命令行操作"><a href="#1-HDFS-命令行操作" class="headerlink" title="1. HDFS 命令行操作"></a>1. HDFS 命令行操作</h3><table>
<thead>
<tr>
<th align="center">命令</th>
<th align="center">解析</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">hdfs dfs -help</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">hdfs dfs -ls &#x2F;</td>
<td align="center">查看HDFS根目录下目录和文件</td>
<td align="center">-R选项递归展示</td>
</tr>
<tr>
<td align="center">hdfs dfs -mkdir &#x2F;mywork</td>
<td align="center">根目录下创建文件夹</td>
<td align="center">-p选项多级目录</td>
</tr>
<tr>
<td align="center">hdfs dfs -put a.txt &#x2F;mywork</td>
<td align="center">虚拟机本地文件上传到HDFS中</td>
<td align="center">-f 强制覆盖</td>
</tr>
<tr>
<td align="center">hdfs dfs -get &#x2F;mywork&#x2F;a.txt &#x2F;root&#x2F;Downloads</td>
<td align="center">HDFS中文件下载到虚拟机本地</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">hdfs dfs -cp &#x2F;mywork&#x2F;a.txt &#x2F;mywork&#x2F;t1</td>
<td align="center">HDFS中文件复制到目录</td>
<td align="center">若复制到文件，即复制+重命名</td>
</tr>
<tr>
<td align="center">hdfs dfs -mv &#x2F;mywork&#x2F;a.txt &#x2F;input&#x2F;</td>
<td align="center">HDFS中文件移动到目录</td>
<td align="center">若移动到文件，即移动+重命名</td>
</tr>
<tr>
<td align="center">hdfs dfs -cat &#x2F;input&#x2F;word.txt</td>
<td align="center">HDFS中查看文件内容</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">hdfs dfs -rm &#x2F;imput&#x2F;a.txt</td>
<td align="center">HDFS中删除文件</td>
<td align="center">-r选项删除目录</td>
</tr>
<tr>
<td align="center">hdfs dfs -df&#x2F;</td>
<td align="center">查看HDFS可用空间</td>
<td align="center"></td>
</tr>
</tbody></table>
<h3 id="2-HDFS-Java-API-操作"><a href="#2-HDFS-Java-API-操作" class="headerlink" title="2. HDFS Java API 操作"></a>2. HDFS Java API 操作</h3><p>使用 HDFS Java API 可以远程对 HDFS 中文件进行创建、上传、下载、删除、读写等操作。</p>
<h4 id="1-新建-Map-x2F-Reduce-项目和测试类"><a href="#1-新建-Map-x2F-Reduce-项目和测试类" class="headerlink" title="1) 新建 Map&#x2F;Reduce 项目和测试类"></a>1) 新建 Map&#x2F;Reduce 项目和测试类</h4><h5 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h5><p>在 Testfiles 类中添加一个<strong>用于创建目录</strong>的 createDir() 测试方法，该方法可以创建新目录<br>。</p>
<h5 id="上传-Windows-本地文件"><a href="#上传-Windows-本地文件" class="headerlink" title="上传 Windows 本地文件"></a>上传 Windows 本地文件</h5><p>在 Testfiles 类中添加一个<strong>用于上传文件</strong>的 putFiles() 测试方法，该方法用于从 Windows 系统本地上传多个文件到集群。</p>
<h5 id="下载文件到本地"><a href="#下载文件到本地" class="headerlink" title="下载文件到本地"></a>下载文件到本地</h5><p>在 Testfiles 类中添加一个<strong>用于下载文件</strong>的 getFiles() 测试方法，该方法通过正则表达式过滤出以“txt”为文件扩展名的文件并下载。</p>
<h5 id="删除文件（或目录）"><a href="#删除文件（或目录）" class="headerlink" title="删除文件（或目录）"></a>删除文件（或目录）</h5><p>在 Testfiles 类中添加一个<strong>用于删除文件（或目录）</strong>的 deleteFiles() 测试方法，该方法用于从 HDFS 中删除文件（或目录）。</p>
<h5 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h5><p>在 Testfiles 类中添加一个<strong>用于写入数据到文件</strong>的 writeHDFS() 测试方法，该方法用于向 HDFS 中写入文件。</p>
<h5 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h5><p>在 Testfiles 类中添加一个<strong>用于读取文件数据</strong>的 readHDFS() 测试方法，该方法可以分行读取文件数据。</p>

        </div>
        <div id="post-footer">
            <div class="avatar" >
                <img src="http://example.com/author.jpg" alt="avatar"/>
                
                <a href="javascript:void(0)" class="high-song">high起来 &#128541;</a>
                
                
                <a href="javascript:void(0)" class="donate fa">赠我一杯 &#128536;</a>
                
            </div>
            <ul class="author-profile-section">
                <li>
                  
                  作者:
                  
                    
                    <a href="/about.html">Koi_NL</a>
                </li>
                
                <li>发表日期: <span>2022-09-07  12:18:31</span></li>
                
                <li>最后编辑日期: <span>2022-09-15  20:40:46</span></li>
                
                <li class="post-category">
                    文章分类:
                    
                    <a href="/categories/Hadoop/">Hadoop</a>
                    
                </li>
                <li class="post-tags">
                    文章标签:
                    
                </li>
                
                <li> 版权声明: <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/" target="_blank">
知识共享署名-非商业性使用-禁止演绎 3.0 未本地化版本许可协议（CC BY-NC-ND 3.0）
</a></li>
                
            </ul>
            <div id="donate-wrap">
                
                
                
                <img src="http://example.com/alipay.jpg" alt="支付宝付款" class="donate-img">
                
                <img src="http://example.com/wechat.png" alt="微信付款" class="donate-img">
                
                
            </div>
        </div>
    </article>
    <div class="article-nav">
        
        <a href="/posts/hadoop02/" class="pre-post fa fa-caret-left">第二章  磁盘I/O操作</a>
        
        
        <a href="/posts/DPaA04/" class="next-post fa">第四章  数据预处理</a>
        
    </div>
    
    <div id="comments">
        

<script>
  gitalk.render("comments");
</script>



    </div>
    
</div>


    </div>
    <footer id="footer">
    
    <div class="social">
        
        <a href="https://www.example1.com" class="fa fa-free-code-camp" target="_blank" title="freecodecamp"></a>
        
        <a href="https://www.example2.com" class="fa fa-github" target="_blank" title="Follow me~"></a>
        
    </div>
    
    <div>
        
        <a href="/" class="copyright-links">Koi_NL</a>&copy;2015 - 2023.All Rights
        Reserved.
    </div>
    <p>Powered by <a href="https://hexo.io" class="copyright-links" target="_blank">Hexo</a> | Theme by <a
                href="https://github.com/GeekaholicLin" class="copyright-links" target="_blank">GeekaholicLin</a>
    </p>
    
    
    <p>
        <span id="busuanzi_container_site_uv" class="fa fa-bar-chart">
        欢迎第<span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span>位小伙伴~
        </span>
    </p>
    
</footer>

</div>
    <ul id="tools">
    <li class="totop-btn fa fa-angle-up"></li>
    <li class="exchange-btn fa fa-exchange"></li>
  
    <li class="toc-btn fa fa-list-ul"></li>
    
    

    
    <li class="comment-btn fa fa-comments-o">
        <a href="#comments" title="comments"></a>
    </li>
    
</ul>
<p id="process"></p>
<div id="search-overlay">
    <div class="search-area-wrap">
        <div id="search-area">
            <div class="input-wrap focus">
                <i class="fa fa-search" aria-hidden="true"></i>
                <input id="search-input" autofocus autocomplete="off" type="text"
                       placeholder="search this website..."/>
            </div>
            <ul id="search-result">
                <li class="load-first"><i class="fa fa-spinner fa-pulse"></i></li>
            </ul>
        </div>
    </div>
</div>

    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81HFDS-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">一、HFDS 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-HDFS-%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87%E5%92%8C%E4%B8%8D%E8%B6%B3"><span class="toc-number">1.1.</span> <span class="toc-text">1. HDFS 的设计目标和不足</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-HDFS-%E7%9A%84%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">2. HDFS 的体系结构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E5%9D%97%EF%BC%88block%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">3. 数据块（block）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-NameNode-%E5%92%8C-SecondaryNameNode"><span class="toc-number">1.2.2.</span> <span class="toc-text">4. NameNode 和 SecondaryNameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%85%83%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%88NameNode%EF%BC%89"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">1) 元数据节点（NameNode）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-SecondaryNameNode%EF%BC%88%E8%BE%85%E5%8A%A9%E8%80%85-%C2%B7-%E5%85%83%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%89"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2) SecondaryNameNode（辅助者 · 元数据节点）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%88DataNode%EF%BC%89"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">3) 数据节点（DataNode）</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%BB%8E%E7%8E%B0%E6%9C%89%E9%9B%86%E7%BE%A4%E9%87%8C%E9%9D%A2%E5%8A%A8%E6%80%81%E5%A2%9E%E5%8A%A0%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9%EF%BC%8C%E6%80%8E%E4%B9%88%E7%A0%B4%EF%BC%9F"><span class="toc-number">1.2.2.3.1.</span> <span class="toc-text">从现有集群里面动态增加一个数据节点，怎么破？</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E9%94%99%E8%AF%AF%E4%B8%8E%E6%81%A2%E5%A4%8D"><span class="toc-number">2.</span> <span class="toc-text">二、数据错误与恢复</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-block-%E6%8D%9F%E5%9D%8F%E5%A4%84%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">1. block 损坏处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-NameNode-%E5%92%8C-DataNode-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">2. NameNode 和 DataNode 错误处理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-NameNode-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86"><span class="toc-number">2.2.1.</span> <span class="toc-text">1) NameNode 错误处理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81HDFS%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6"><span class="toc-number">3.</span> <span class="toc-text">三、HDFS的运行机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-number">3.1.</span> <span class="toc-text">1. 副本机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%BF%83%E8%B7%B3%E6%9C%BA%E5%88%B6"><span class="toc-number">3.2.</span> <span class="toc-text">2. 心跳机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%89%AF%E6%9C%AC%E6%94%BE%E7%BD%AE%E4%B8%8E%E6%9C%BA%E6%9E%B6%E6%84%9F%E5%BA%94%E7%AD%96%E7%95%A5"><span class="toc-number">3.3.</span> <span class="toc-text">3. 副本放置与机架感应策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%89%AF%E6%9C%AC%E6%94%BE%E7%BD%AE"><span class="toc-number">3.3.1.</span> <span class="toc-text">1) 副本放置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%9C%BA%E6%9E%B6%E6%84%9F%E5%BA%94%EF%BC%88rack-aware%EF%BC%89"><span class="toc-number">3.3.2.</span> <span class="toc-text">2) 机架感应（rack-aware）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%81%94%E9%82%A6%EF%BC%88Federation%EF%BC%89%E6%9C%BA%E5%88%B6"><span class="toc-number">3.4.</span> <span class="toc-text">4. 联邦（Federation）机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-HA%EF%BC%887-24%E5%B0%8F%E6%97%B6%E4%B8%8D%E4%B8%AD%E6%96%AD%E6%9C%8D%E5%8A%A1%EF%BC%89-%E6%9C%BA%E5%88%B6"><span class="toc-number">3.5.</span> <span class="toc-text">5. HA（7*24小时不中断服务） 机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.6.</span> <span class="toc-text">6. 安全模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6"><span class="toc-number">3.7.</span> <span class="toc-text">7. 垃圾回收</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81HDFS-%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">四、HDFS 的工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.</span> <span class="toc-text">1. 启动流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%AF%BB%E6%B5%81%E7%A8%8B"><span class="toc-number">4.2.</span> <span class="toc-text">2. 读流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%86%99%E6%B5%81%E7%A8%8B"><span class="toc-number">4.3.</span> <span class="toc-text">3. 写流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B"><span class="toc-number">4.4.</span> <span class="toc-text">4. 删除流程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E4%BD%BF%E7%94%A8-HDFS-%E5%91%BD%E4%BB%A4%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.1.</span> <span class="toc-text">1) 使用 HDFS 命令删除文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E4%BD%BF%E7%94%A8-Java-API-%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6"><span class="toc-number">4.4.2.</span> <span class="toc-text">2) 使用 Java API 删除文件</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81HDFS-%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">5.</span> <span class="toc-text">五、HDFS 的基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-HDFS-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C"><span class="toc-number">5.1.</span> <span class="toc-text">1. HDFS 命令行操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-HDFS-Java-API-%E6%93%8D%E4%BD%9C"><span class="toc-number">5.2.</span> <span class="toc-text">2. HDFS Java API 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%96%B0%E5%BB%BA-Map-x2F-Reduce-%E9%A1%B9%E7%9B%AE%E5%92%8C%E6%B5%8B%E8%AF%95%E7%B1%BB"><span class="toc-number">5.2.1.</span> <span class="toc-text">1) 新建 Map&#x2F;Reduce 项目和测试类</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95"><span class="toc-number">5.2.1.1.</span> <span class="toc-text">创建目录</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0-Windows-%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6"><span class="toc-number">5.2.1.2.</span> <span class="toc-text">上传 Windows 本地文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="toc-number">5.2.1.3.</span> <span class="toc-text">下载文件到本地</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%EF%BC%88%E6%88%96%E7%9B%AE%E5%BD%95%EF%BC%89"><span class="toc-number">5.2.1.4.</span> <span class="toc-text">删除文件（或目录）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-number">5.2.1.5.</span> <span class="toc-text">写入数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">5.2.1.6.</span> <span class="toc-text">读取数据</span></a></li></ol></li></ol></li></ol></li></ol>


    
<script src="/js/highsong.js"></script>





<script src="/js/search.js"></script>

<script type="text/javascript">
    //theme config datas
    var copyrightObj = {};
    copyrightObj.enable = 'true';
    copyrightObj.triggerCopyLength = '200';
    copyrightObj.appendText = '商业转载请联系作者获得授权,非商业转载请注明出处 © example';
    var leancloudObj = {};
    leancloudObj.enable = 'true';
    leancloudObj.className = 'BlogCounter';
    leancloudObj.limits = '10';
</script>
<script type="text/javascript">
    var search = {};
    var search_path = "search.xml";
    if (!search_path) {
        search_path = "search.xml";
    }
    search.path = "/" + search_path;
    search.func =  _ajax.init();
</script>

<script src="/js/app.js"></script>



</body>
</html>