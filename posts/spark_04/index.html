<!doctype html>
<html>
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable"  content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no">
    
    
    <!--Simple SEO-->


<meta name="robots" content=all />
<meta name="google" content=all />
<meta name="googlebot" content=all />
<meta name="verify" content=all />
    <!--Title-->

<title>第4章  Spark SQL结构化数据文件处理 | 锦鲤未离</title>

<link rel="alternate" href="/atom.xml" title="锦鲤未离" type="application/atom+xml">


<link rel="icon" href="/favicon.ico">

    

<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/css/pages/post.css">
<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/thirdParty/highlight/github.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">


    <!--script-->



<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>

<script>
  var admin = "GeekaholicLin";
  admin = admin.split(",");
  var gitalk = new Gitalk({
    clientID: "xxxxx",
    clientSecret: "xxxxx",
    repo: "geekaholiclin.github.io",
    owner: "GeekaholicLin",
    admin: admin,
    id: decodeURIComponent(location.pathname),
    distractionFreeMode: false
  })

</script>

    
    
<meta name="generator" content="Hexo 6.1.0"></head>

<body id="normal">
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<style>
    header{ top: 71px; position: absolute!important;}
    #container{padding-top: 151px!important;}
</style>
<div style="position:fixed;z-index:9999;left:0;top:0;width:100%;height:70px;background-color:#e0e0e0;color:#396CA5;border-bottom:1px solid #cecece;text-align:center;line-height:70px;white-space: nowrap;overflow: hidden;text-overflow: ellipsis">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<div id="wrap">
    <header  style="position: absolute;" >
    <div id="site-meta">
        <a href="/" id="logo">
            <h1 class="title">锦鲤未离</h1>
        </a>
        
        <h2 class="subtitle">KoiNL</h2>
        
    </div>
    <ul id="nav">
        
            <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
        
            <li><a href="/atom.xml"><i class="fa fa-rss"></i>RSS</a></li>
        
        <li id="search"><a href="javascript:void(0)"><i class="fa fa-search"></i>搜索</a></li>
    </ul>
</header>

    <div id="container">
        
<ul id="sidebar">
    
    
<li class="widget notification">
    <i class="fa fa-bell-o"></i>
    <div>
        
<p>主题ylion v0.0.0版本即将上线，敬请期待~！
主题作者：<a href="https://github.com/GeekaholicLin"
title="fork me" target="_blank">Geekaholic</a></p>
    </div>
</li>

    
    
<li class="widget widget-normal category">
    <h3 class="fa fa-th widget-title">分类</h3>
    <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Applied-Statistics/"><i class="fa" aria-hidden="true">Applied Statistics</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Structure-and-Algorithm/"><i class="fa" aria-hidden="true">Data Structure and Algorithm</i></a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Mining/"><i class="fa" aria-hidden="true">Data-Mining</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Processing-and-Analysing/"><i class="fa" aria-hidden="true">Data-Processing-and-Analysing</i></a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/"><i class="fa" aria-hidden="true">Hadoop</i></a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/"><i class="fa" aria-hidden="true">Linux</i></a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MATLAB/"><i class="fa" aria-hidden="true">MATLAB</i></a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/"><i class="fa" aria-hidden="true">Python</i></a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SqlServer/"><i class="fa" aria-hidden="true">SqlServer</i></a><span class="category-list-count">17</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/"><i class="fa" aria-hidden="true">java</i></a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/"><i class="fa" aria-hidden="true">spark</i></a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"><i class="fa" aria-hidden="true">时间序列分析</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B5%8B%E8%AF%95%E5%8C%BA/"><i class="fa" aria-hidden="true">测试区</i></a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa" aria-hidden="true">深度卷积神经网络</i></a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%B5%E5%AD%90%E8%AE%BE%E5%A4%87/"><i class="fa" aria-hidden="true">电子设备</i></a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%80%83%E8%AF%95/"><i class="fa" aria-hidden="true">考试</i></a><span class="category-list-count">1</span></li></ul>
</li>


    
    
<li class="widget widget-normal archive">
  <h3 class="fa fa-archive widget-title">归档</h3>
    <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/"><i class="fa" aria-hidden="true">三月 2023</i></a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/"><i class="fa" aria-hidden="true">二月 2023</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/"><i class="fa" aria-hidden="true">十一月 2022</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/"><i class="fa" aria-hidden="true">十月 2022</i></a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/"><i class="fa" aria-hidden="true">九月 2022</i></a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/"><i class="fa" aria-hidden="true">八月 2022</i></a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/"><i class="fa" aria-hidden="true">七月 2022</i></a><span class="archive-list-count">25</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/"><i class="fa" aria-hidden="true">六月 2022</i></a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/05/"><i class="fa" aria-hidden="true">五月 2022</i></a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/04/"><i class="fa" aria-hidden="true">四月 2022</i></a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/"><i class="fa" aria-hidden="true">三月 2022</i></a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/"><i class="fa" aria-hidden="true">二月 2022</i></a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/"><i class="fa" aria-hidden="true">一月 2022</i></a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1999/01/"><i class="fa" aria-hidden="true">一月 1999</i></a><span class="archive-list-count">2</span></li></ul>
</li>


    
    
<li class="widget widget-normal popular-posts" id="popular-posts">
    <h3 class="fa fa-thermometer-3 widget-title">热门文章</h3>
    <ul id="popular-content">
        <li class="load-first"><i class="fa fa-spinner fa-pulse"></i></li>
    </ul>
</li>

    
    

    
    
<li class="widget widget-normal friends-link">
    <h3 class="fa fa-globe widget-title">友链</h3><br/>

    
        <a href="http://geekaholiclin.github.io" class="fa" target="_blank">主题作者</a>

    

</li>

    
</ul>


        <div id="main">
    <article id="post">
        <div id="post-header">

            <h1 id="第4章  Spark SQL结构化数据文件处理">
                
                第4章  Spark SQL结构化数据文件处理
                
            </h1>
            <div class="article-meta">
    
    
    <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
        <span>spark</span>
    </span>
    
    
    <span class="fa-wrap">
         <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
            null
            
        </span>
    </span>
    
    
    <span class="fa-wrap">
        <i class="fa fa-clock-o"></i>
        <span class="date-meta ">2023/03/31</span>
    </span>
    
    
    <span class="fa-wrap">
            <i class="fa fa-thermometer-three-quarters"></i>
        <span class="hits hits-meta " data-leadcloud-title="第4章  Spark SQL结构化数据文件处理"
              data-leadcloud-url="/posts/spark_04/"><i class="fa fa-spinner fa-spin"></i></span>
    </span>
    
    
</div>

            
            
        </div>
        
        <div id="post-body">
            <p>本章目的在于如何使用Spark SQL模块来处理结构化数据，结构化数据即以<strong>关系型数据库表</strong>形式管理的数据。</p>
<span id="more"></span>

<p>首先，本章讲解在Linux系统下对结构化数据的处理。Spark SQL模块让用户可以通过<strong>SQL</strong>、<strong>DataFrame API</strong> 和 **DataSet API **三种方式来实现对结构化数据的处理。<br>在Spark-Shell操作下，RDD很容易就能转换成为DataFrame。那么在Windows系统下呢？又该如何使RDD转换成为DataFrame？</p>
<p>启动Spark-Shell的命令如下：<code>$ spark-shell --master local[2]</code>；如不能正常运行，可跳转到spark安装目录，使用命令 <code>$ bin/spark-shell</code> 启动Spark-shell。</p>
<details ><summary>文件：no4-createDataFrame.txt，该文件用于本章例子</summary><div class="fold-content"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将要用到的文件no4-createDataFrame.txt</span></span><br><span class="line">[root@hadoop01 ~]# hdfs dfs -cat /sparktest/data/no4-createDataFrame.txt</span><br><span class="line">zhangsan 20</span><br><span class="line">lisi 29</span><br><span class="line">wangwu 25</span><br><span class="line">zhaoliu 30</span><br><span class="line">tianqi 35</span><br><span class="line">jerry 40</span><br></pre></td></tr></table></figure></div></details>

<h2 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h2><h3 id="DataFrame的创建"><a href="#DataFrame的创建" class="headerlink" title="DataFrame的创建"></a>DataFrame的创建</h3><p>创建DataFrame的方式是从一个已经存在的RDD调用toDF()方法进行转换，得到DataFrame；或者通过Spark读取数据源直接创建。<br>这里提供两种成员函数printSchema()和show()，作用分别为打印当前对象的Schema元数据信息和结果数据。</p>
<details ><summary>创建DataFrame的两种方式及部分成员函数</summary><div class="fold-content"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># 通过文件直接创建DataFrame。除了读取text(.txt)文件，还可以读取csv、json、parquet等 | 创建方式1</span><br><span class="line">scala&gt; val personDF=spark.read.text(&quot;/sparktest/data/no4-createDataFrame.txt&quot;)</span><br><span class="line">personDF: org.apache.spark.sql.DataFrame = [value: string]</span><br><span class="line"></span><br><span class="line"># 打印当前对象的Schema元数据信息：String数据类型，且可为空。</span><br><span class="line">scala&gt; personDF.printSchema()</span><br><span class="line">root</span><br><span class="line"> |-- value: string (nullable = true)</span><br><span class="line"></span><br><span class="line"># 打印当前DataFrame的结果数据</span><br><span class="line">scala&gt; personDF.show()</span><br><span class="line">+-----------+       </span><br><span class="line">|      value    |</span><br><span class="line">+-----------+</span><br><span class="line">|zhangsan 20|</span><br><span class="line">|    lisi 29|</span><br><span class="line">|  wangwu 25|</span><br><span class="line">| zhaoliu 30|</span><br><span class="line">|  tianqi 35|</span><br><span class="line">|   jerry 40|</span><br><span class="line">+-----------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 从已经存在的RDD进行转换得到DataFrame，首先获取数据</span><br><span class="line"># 第一步</span><br><span class="line">scala&gt; case class Person(name:String,age:Int)</span><br><span class="line">defined class Person</span><br><span class="line"># 以上三步可直接写成：</span><br><span class="line">scala&gt; val pDF=sc.textFile(&quot;/sparktest/data/no4-createDataFrame.txt&quot;).map(_.split(&quot; &quot;)).map(x =&gt; Person(x(0),x(1).toInt)).toDF()</span><br><span class="line">scala&gt; pDF.show</span><br><span class="line">+--------+---+      </span><br><span class="line">|    name|age|</span><br><span class="line">+--------+---+</span><br><span class="line">|zhangsan| 20|</span><br><span class="line">|    lisi| 29|</span><br><span class="line">|  wangwu| 25|</span><br><span class="line">| zhaoliu| 30|</span><br><span class="line">|  tianqi| 35|</span><br><span class="line">|   jerry| 40|</span><br><span class="line">+--------+---+</span><br></pre></td></tr></table></figure></div></details>

<h3 id="DataFrame的常用操作"><a href="#DataFrame的常用操作" class="headerlink" title="DataFrame的常用操作"></a>DataFrame的常用操作</h3><p>DataFrame提供了两种语法风格，分别为DSL风格操作和SQL风格操作。对应的就是DataFrame API 、SQL两种方式。<br>DSL风格</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">#查看name 字段的数据，PersonDF会随变量名的变化而变化。</span><br><span class="line">#以下五种方式可同义替代。但第四种方法不推荐！原因是因为某些代码可能不支持！</span><br><span class="line">pDF.select(pDF.col(&quot;name&quot;),pDF.col(&quot;age&quot;)).show</span><br><span class="line">pDF.select(pDF(&quot;name&quot;),pDF(&quot;age&quot;)).show</span><br><span class="line">pDF.select(col(&quot;name&quot;),col(&quot;age&quot;)).show</span><br><span class="line">pDF.select(&quot;name&quot;,&quot;age&quot;).show</span><br><span class="line"># pDF.select(&quot;name&quot;,&quot;age&quot;+1).show 不可运行！</span><br><span class="line"># 但其他四个可运行！例如“$&quot;age&quot;+1”、“col(&quot;age&quot;)+1”</span><br><span class="line"># 请注意可以通过as来重命名列名</span><br><span class="line">pDF.select($&quot;name&quot;,($&quot;age&quot;+1).as(&quot;new_age&quot;)).show</span><br><span class="line"></span><br><span class="line">#条件过滤（对应Where语句）</span><br><span class="line">pDF.filter($&quot;age&quot; &gt;30).show</span><br><span class="line"></span><br><span class="line">#分组（对应Group By语句）</span><br><span class="line">pDF.groupBy(&quot;age&quot;).count().show</span><br><span class="line"></span><br><span class="line">#排序（对应Order By语句）</span><br><span class="line">pDF.sort($&quot;age&quot;.desc).show</span><br></pre></td></tr></table></figure>
<h4 id="SQL风格操作"><a href="#SQL风格操作" class="headerlink" title="SQL风格操作"></a>SQL风格操作</h4><p>将DataFrame注册成一个临时表就可以进行SQL风格操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; pDF.registerTempTable(&quot;t_koinl&quot;)</span><br><span class="line">scala&gt; spark.sql(&quot;select name, age + 1 from t_koinl&quot;).show</span><br></pre></td></tr></table></figure>
<h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><h2 id="RDD转换为DataFrame"><a href="#RDD转换为DataFrame" class="headerlink" title="RDD转换为DataFrame"></a>RDD转换为DataFrame</h2><p>在上文中，有说明在Spark-shell中如何将RDD转换为DataFrame，在本小节中，来说明如何在Windows系统下开发Scala代码。</p>
<p>一般情况下，可以使用两种方法来实现。第一种方法是利用反射机制来推断包含特定类型对象的Schema。当<strong>case类不能提前定义，即未知数据结构</strong>时，应通过编程接口构造一个Schema，并将其应用在已知的RDD数据中。 </p>
<h2 id="Spark-SQL操作数据源"><a href="#Spark-SQL操作数据源" class="headerlink" title="Spark SQL操作数据源"></a>Spark SQL操作数据源</h2><h3 id="操作MySQL"><a href="#操作MySQL" class="headerlink" title="操作MySQL"></a>操作MySQL</h3><h4 id="读取MySQL种数据"><a href="#读取MySQL种数据" class="headerlink" title="读取MySQL种数据"></a>读取MySQL种数据</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Properties</span><br><span class="line">import org.apache.spark.sql.&#123;DataFrame, SaveMode,SparkSession&#125;</span><br><span class="line"> </span><br><span class="line">object sparkSqlMysql &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //创建sparkSession对象</span><br><span class="line">    val spark: SparkSession = SparkSession.builder()</span><br><span class="line">      .appName(&quot;sparkSqlMysql&quot;)</span><br><span class="line">      .master(&quot;local[2]&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    //创建Properties对象，配置连接mysql的用户名和密码</span><br><span class="line">    val prop: prop =new Properties()</span><br><span class="line">    prop.setProperty(&quot;user&quot;,&quot;root&quot;)</span><br><span class="line">    prop.setProperty(&quot;password&quot;,&quot;123456&quot;)</span><br><span class="line">    //从数据库里读取数据</span><br><span class="line">    val mysqlDF: DataFrame = spark.read.jdbc(&quot;jdbc:mysql://127.0.0.1:3306/spark&quot;, &quot;person&quot;, prop)</span><br><span class="line">    //显示Mysql中表数据</span><br><span class="line">    mysqlDF.show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="写入数据到MySQL"><a href="#写入数据到MySQL" class="headerlink" title="写入数据到MySQL"></a>写入数据到MySQL</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Properties</span><br><span class="line">import org.apache.spark.rdd.RDD</span><br><span class="line">import org.apache.spark.sql.&#123;DataFrame, SaveMode,SparkSession&#125;</span><br><span class="line"> case class Person(id:Int,name:String,age:Int)</span><br><span class="line"></span><br><span class="line">object sparkSqlMysql &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    //创建sparkSession对象</span><br><span class="line">    val spark: SparkSession = SparkSession.builder()</span><br><span class="line">      .appName(&quot;sparkSqlMysql&quot;)</span><br><span class="line">      .master(&quot;local[2]&quot;)</span><br><span class="line">      .getOrCreate()</span><br><span class="line">    val sc = spark.sparkContext.parallelize(Array(&quot;3,wangwu,22&quot;,&quot;4,zhaoliu,26&quot;))</span><br><span class="line">    //切分读取数据</span><br><span class="line">    val data: RDD[Array[String]] = sc.map(_.split(&quot;,&quot;))</span><br><span class="line">    //RDD关联Person</span><br><span class="line">    val personRdd: RDD[Person] = data.map(x =&gt; Person(x(0)。toInt,x(1), x(2).toLong))</span><br><span class="line">    //导入隐式转换</span><br><span class="line">    import spark.implicits._</span><br><span class="line">    //将RDD转换成DataFrame</span><br><span class="line">    val personDF: DataFrame = personRdd.toDF()</span><br><span class="line">    //创建Properties对象，配置连接mysql的用户名和密码</span><br><span class="line">    val prop =new Properties()</span><br><span class="line">    prop.setProperty(&quot;user&quot;,&quot;root&quot;)</span><br><span class="line">    prop.setProperty(&quot;password&quot;,&quot;123456&quot;)</span><br><span class="line">    //将personDF写入MySQL</span><br><span class="line"> </span><br><span class="line">    personDF.write.mode(SaveMode.Append).jdbc(&quot;jdbc:mysql://127.0.0.1:3306/spark?useUnicode=true&amp;characterEncoding=utf8&quot;,&quot;person&quot;,prop)</span><br><span class="line">    personDF.show()</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="操作Hive"><a href="#操作Hive" class="headerlink" title="操作Hive"></a>操作Hive</h3>
        </div>
        <div id="post-footer">
            <div class="avatar" >
                <img src="http://example.com/author.jpg" alt="avatar"/>
                
                <a href="javascript:void(0)" class="high-song">high起来 &#128541;</a>
                
                
                <a href="javascript:void(0)" class="donate fa">赠我一杯 &#128536;</a>
                
            </div>
            <ul class="author-profile-section">
                <li>
                  
                  作者:
                  
                    
                    <a href="/about.html">Koi_NL</a>
                </li>
                
                <li>发表日期: <span>2023-03-31  11:48:40</span></li>
                
                <li>最后编辑日期: <span>2023-04-01  22:09:52</span></li>
                
                <li class="post-category">
                    文章分类:
                    
                    <a href="/categories/spark/">spark</a>
                    
                </li>
                <li class="post-tags">
                    文章标签:
                    
                </li>
                
                <li> 版权声明: <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/" target="_blank">
知识共享署名-非商业性使用-禁止演绎 3.0 未本地化版本许可协议（CC BY-NC-ND 3.0）
</a></li>
                
            </ul>
            <div id="donate-wrap">
                
                
                
                <img src="http://example.com/alipay.jpg" alt="支付宝付款" class="donate-img">
                
                <img src="http://example.com/wechat.png" alt="微信付款" class="donate-img">
                
                
            </div>
        </div>
    </article>
    <div class="article-nav">
        
        <a href="/posts/spark_05/" class="pre-post fa fa-caret-left">第5章  HBase 分布式数据库</a>
        
        
        <a href="/posts/spark_01/" class="next-post fa">第1章  Scala语言基础.</a>
        
    </div>
    
    <div id="comments">
        

<script>
  gitalk.render("comments");
</script>



    </div>
    
</div>


    </div>
    <footer id="footer">
    
    <div class="social">
        
        <a href="https://www.example1.com" class="fa fa-free-code-camp" target="_blank" title="freecodecamp"></a>
        
        <a href="https://www.example2.com" class="fa fa-github" target="_blank" title="Follow me~"></a>
        
    </div>
    
    <div>
        
        <a href="/" class="copyright-links">Koi_NL</a>&copy;2015 - 2023.All Rights
        Reserved.
    </div>
    <p>Powered by <a href="https://hexo.io" class="copyright-links" target="_blank">Hexo</a> | Theme by <a
                href="https://github.com/GeekaholicLin" class="copyright-links" target="_blank">GeekaholicLin</a>
    </p>
    
    
    <p>
        <span id="busuanzi_container_site_uv" class="fa fa-bar-chart">
        欢迎第<span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span>位小伙伴~
        </span>
    </p>
    
</footer>

</div>
    <ul id="tools">
    <li class="totop-btn fa fa-angle-up"></li>
    <li class="exchange-btn fa fa-exchange"></li>
  
    <li class="toc-btn fa fa-list-ul"></li>
    
    

    
    <li class="comment-btn fa fa-comments-o">
        <a href="#comments" title="comments"></a>
    </li>
    
</ul>
<p id="process"></p>
<div id="search-overlay">
    <div class="search-area-wrap">
        <div id="search-area">
            <div class="input-wrap focus">
                <i class="fa fa-search" aria-hidden="true"></i>
                <input id="search-input" autofocus autocomplete="off" type="text"
                       placeholder="search this website..."/>
            </div>
            <ul id="search-result">
                <li class="load-first"><i class="fa fa-spinner fa-pulse"></i></li>
            </ul>
        </div>
    </div>
</div>

    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#DataFrame"><span class="toc-number">1.</span> <span class="toc-text">DataFrame</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DataFrame%E7%9A%84%E5%88%9B%E5%BB%BA"><span class="toc-number">1.1.</span> <span class="toc-text">DataFrame的创建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DataFrame%E7%9A%84%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.</span> <span class="toc-text">DataFrame的常用操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SQL%E9%A3%8E%E6%A0%BC%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.1.</span> <span class="toc-text">SQL风格操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dataset"><span class="toc-number">1.3.</span> <span class="toc-text">Dataset</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RDD%E8%BD%AC%E6%8D%A2%E4%B8%BADataFrame"><span class="toc-number">2.</span> <span class="toc-text">RDD转换为DataFrame</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-SQL%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="toc-number">3.</span> <span class="toc-text">Spark SQL操作数据源</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9CMySQL"><span class="toc-number">3.1.</span> <span class="toc-text">操作MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96MySQL%E7%A7%8D%E6%95%B0%E6%8D%AE"><span class="toc-number">3.1.1.</span> <span class="toc-text">读取MySQL种数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0MySQL"><span class="toc-number">3.1.2.</span> <span class="toc-text">写入数据到MySQL</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%93%8D%E4%BD%9CHive"><span class="toc-number">3.2.</span> <span class="toc-text">操作Hive</span></a></li></ol></li></ol>


    
<script src="/js/highsong.js"></script>





<script src="/js/search.js"></script>

<script type="text/javascript">
    //theme config datas
    var copyrightObj = {};
    copyrightObj.enable = 'true';
    copyrightObj.triggerCopyLength = '200';
    copyrightObj.appendText = '商业转载请联系作者获得授权,非商业转载请注明出处 © example';
    var leancloudObj = {};
    leancloudObj.enable = 'true';
    leancloudObj.className = 'BlogCounter';
    leancloudObj.limits = '10';
</script>
<script type="text/javascript">
    var search = {};
    var search_path = "search.xml";
    if (!search_path) {
        search_path = "search.xml";
    }
    search.path = "/" + search_path;
    search.func =  _ajax.init();
</script>

<script src="/js/app.js"></script>



</body>
</html>